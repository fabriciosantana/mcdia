{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d851e39",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/fabriciosantana/mcdia/blob/main/01-icd/assignments/02-final/02-analisar-discursos-final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affddafa",
   "metadata": {
    "id": "affddafa"
   },
   "source": [
    "# Análise de discursos da 56ª Legislatura (2019-2023) do plenário do Senado Federal\n",
    "\n",
    "Fabricio Fernandes Santana  \n",
    "Disciplina: Fundamentos da Ciência de Dados no Setor Público - 2025.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1362906",
   "metadata": {
    "id": "b1362906"
   },
   "source": [
    "## 1. Introdução\n",
    "Este projeto analisa integralmente os discursos proferidos no plenário do Senado Federal durante a 56ª Legislatura (2019-2023). A investigação combina preparação de dados, análises descritivas, modelagem supervisionada para estimar o partido do orador a partir do texto e modelagem não supervisionada para mapear temas latentes. A questão orientadora é dupla: verificar se o conteúdo textual distingue legendas de forma robusta e, simultaneamente, se os tópicos emergentes revelam agendas que corroboram ou tensionam o posicionamento declarado dos partidos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1b0396",
   "metadata": {},
   "source": [
    "### 1.1 Problema público, narrativa e decisão\n",
    "O Senado exerce papel central na formulação de políticas e na sinalização de prioridades das legendas. Sem monitoramento contínuo, torna-se difícil cobrar coerência entre os discursos parlamentares e a agenda oficial dos partidos, sobretudo em contextos de crise sanitária, recuperação econômica e disputa eleitoral. Este trabalho propõe usar dados abertos de pronunciamentos tanto para estimar o partido provável pelo conteúdo (abordagem supervisionada) quanto para identificar temas dominantes sem rótulos (abordagem não supervisionada), oferecendo um mecanismo de vigilância cívica sobre o alinhamento entre fala, programa partidário e agenda efetivamente debatida."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a30ef29",
   "metadata": {
    "id": "7a30ef29"
   },
   "source": [
    "## 2. Análise Descritiva Preliminar\n",
    "O dataset proveniente do portal de Dados Abertos do Senado é carregado a partir do repositório público no Hugging Face. Antes de qualquer modelagem, são inspecionados tipos de dados, completude e distribuição temporal, de autoria e de partidos, de modo a contextualizar o corpus, orientar decisões de limpeza e alimentar de forma consistente tanto o classificador supervisionado quanto o modelo temático não supervisionado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7742f25",
   "metadata": {},
   "source": [
    "### 2.0 Referência de preparação de dados\n",
    "A base deriva do portal Dados Abertos do Senado (56ª Legislatura). O pipeline documentado em `01-preparar-base-discursos.ipynb` executa extração via API, limpeza de HTML e acentuação, recorte temporal, deduplicação e padronização em CSV/Parquet publicada na Hugging Face. Garantias de qualidade incluem checagem de valores ausentes nas colunas-chave (`Data`, `TextoDiscursoIntegral`, `NomeAutor`, `Partido`), filtros de tamanho mínimo e normalização de codificação. A versão final é lida neste notebook para todas as análises subsequentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b84434",
   "metadata": {
    "id": "39b84434"
   },
   "source": [
    "### 2.1 Importar Bibliotecas\n",
    "As bibliotecas utilizadas cobrem manipulação de dados (pandas, numpy), visualização (matplotlib, seaborn), modelagem (scikit-learn) e acesso ao dataset (datasets/Hugging Face). Esse conjunto permite documentar integralmente a preparação e a análise no próprio notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f572e3",
   "metadata": {
    "id": "a5f572e3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from datasets import load_dataset\n",
    "from datasets import load_dataset_builder\n",
    "import re\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0eac2dd",
   "metadata": {
    "id": "f0eac2dd"
   },
   "source": [
    "### 2.2 Carregar Dados\n",
    "O conjunto de discursos é recuperado diretamente do repositório no Hugging Face, garantindo reprodutibilidade. Em seguida, converte-se a coluna de data para `datetime` e exibe-se a dimensão do DataFrame para evidenciar a abrangência da legislatura analisada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a2b5f8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "b5891155ff434ba5a0826ae93e0ee6e7",
      "0271d898dc3c4235b93f02dafc85e1c6",
      "e21606d7189b4df5bf13c5052f3fe14c",
      "c832fdfca7a34576a6279afd8c2a27b9",
      "858619a3f38e42a8ace6b6b01c42ce3e",
      "3fe8b2046c894495aa974515446b6655",
      "cd0a2fa550b248aa8350e2e8e9fef253",
      "3c8fc0b18bb144d7a62e4c64fc2d3923",
      "e97e3f6ef16344649b0d0504c96e01cb",
      "85f3deae3b6347dfa34e8cd82bd5c4ea",
      "f437d0829b434fbba82bf80a4a938584",
      "f46cfa6f94414cdbb751dbd4f137a364",
      "280c0bd307a7483f81b2185fd5030129",
      "90541510d574459c80671b154196a604",
      "c04598c6eb514e5bb4c01988da8b29fd",
      "d7f9611ee05e4c2fabc8fa5facd805c3",
      "ec4d6b50db8e46b8babd29b357a01797",
      "7853efa4b62341899a06a3761ef9023e",
      "264806a8113143c29527a8108d9cc257",
      "30c45db7907145979efbf70026105c7a",
      "8b51a3c5b2244e09957a5b5956d804d2",
      "ecff607df32f4967aad2f161fde623e1",
      "ddbfe45dc76d40cbac88a6a7c375c14e",
      "e21b48a1f60040ff9a6c4376405b6c14",
      "346cf8d5c77b48dea58972a88994e291",
      "639d539e4a9f4a849ba5048365b55755",
      "d8876e49403244e1bbd54decf12887c2",
      "58304f3fa8494f2a823e61208e329273",
      "2df828b1f9134906805a996629fd9a2d",
      "524829815b3740fb8c61d6e8d93359e3",
      "24e5652a74b94dee98bf8cfb52faeb61",
      "2fbb89313111421b8902f32096366f4e",
      "98a891f7985a4e9fb0d56c113c19d114"
     ]
    },
    "id": "54a2b5f8",
    "outputId": "cbfa1eb9-d724-4496-f588-533b28125d29"
   },
   "outputs": [],
   "source": [
    "DATASET_HF_REPO = \"fabriciosantana/discursos-senado-legislatura-56\"\n",
    "DATA_FILE_HF = {\"train\": \"data/full/discursos_2019-02-01_2023-01-31.parquet\"}\n",
    "\n",
    "ds_builder = load_dataset_builder(DATASET_HF_REPO)\n",
    "display(ds_builder.info)\n",
    "\n",
    "dataset = load_dataset(DATASET_HF_REPO, data_files=DATA_FILE_HF)\n",
    "df_raw = dataset[\"train\"].to_pandas()\n",
    "df_raw['Data'] = pd.to_datetime(df_raw['Data'], errors='coerce')\n",
    "\n",
    "print(f'Linhas: {len(df_raw):,} | Colunas: {df_raw.shape[1]}')\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3787e8",
   "metadata": {
    "id": "6d3787e8"
   },
   "source": [
    "### 2.2.1 Analisar a estrutura do dataframe\n",
    "A inspeção de `shape` e `info()` documenta o número de registros, colunas e respectivos tipos, além de indicar campos com valores ausentes. Esse diagnóstico inicial fundamenta as etapas posteriores de higienização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cbe81d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "38cbe81d",
    "outputId": "25a248e3-b1b9-4216-d420-272b202f2207"
   },
   "outputs": [],
   "source": [
    "print(f'Linhas: {df_raw.shape[0]:,} | Colunas: {df_raw.shape[1]}')\n",
    "df_raw.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b66e07",
   "metadata": {
    "id": "86b66e07"
   },
   "source": [
    "### 2.3 Obter uma visão geral dos tipos de dados e da quantidade de valores ausentes por coluna\n",
    "Constrói-se uma tabela que relaciona cada coluna ao seu tipo, número absoluto e percentual de ausências, ordenada pelos casos mais críticos. A leitura dessa tabela prioriza quais variáveis exigem tratamento e evita surpresas no fluxo de modelagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e319a6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "63e319a6",
    "outputId": "524c28bc-182e-4f4e-ab6a-d70e188b5d52"
   },
   "outputs": [],
   "source": [
    "overview = (\n",
    "    pd.DataFrame({\n",
    "        'dtype': df_raw.dtypes.astype(str),\n",
    "        'missing': df_raw.isna().sum()\n",
    "    })\n",
    "    .assign(missing_pct=lambda df: (df['missing'] / len(df_raw) * 100).round(2))\n",
    "    .sort_values('missing', ascending=False)\n",
    ")\n",
    "overview.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d67d638",
   "metadata": {
    "id": "1d67d638"
   },
   "source": [
    "### 2.4 Sintetizar indicadores-chave sobre o volume e a diversidade do corpus de discursos\n",
    "São computadas contagens de discursos, autores, partidos, unidades da federação e datas únicas. Esses indicadores situam a escala do corpus e mostram a diversidade de atores representados na legislatura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770e265e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "770e265e",
    "outputId": "2d6e53c4-5fe2-44b9-eb6e-09dbfb7c62fc"
   },
   "outputs": [],
   "source": [
    "metrics = pd.Series({\n",
    "    'Discursos': len(df_raw),\n",
    "    'Autores unicos': df_raw['NomeAutor'].nunique(),\n",
    "    'Partidos unicos': df_raw['Partido'].nunique(),\n",
    "    'Estados representados': df_raw['UF'].nunique(),\n",
    "    'Datas distintas': df_raw['Data'].nunique()\n",
    "})\n",
    "metrics.to_frame('valor')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b3f26e",
   "metadata": {
    "id": "00b3f26e"
   },
   "source": [
    "### 2.5. Detalhar as colunas com maior incidência de valores faltantes\n",
    "A contagem e o percentual de `NaN` por coluna permitem priorizar o tratamento de campos críticos, especialmente aqueles que impactam a construção de variáveis de tempo, autor e partido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70408f99",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "id": "70408f99",
    "outputId": "07678dde-e296-4d7b-852c-aba320fa4d6f"
   },
   "outputs": [],
   "source": [
    "missing = (\n",
    "    df_raw.isna()\n",
    "        .sum()\n",
    "        .to_frame('faltantes')\n",
    "        .assign(percentual=lambda df: (df['faltantes'] / len(df_raw) * 100).round(2))\n",
    "        .sort_values('faltantes', ascending=False)\n",
    ")\n",
    "missing.head(12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb4379a",
   "metadata": {
    "id": "5cb4379a"
   },
   "source": [
    "### 2.6 Preparar atributos derivados que serão usados na análise exploratória e no modelo supervisionado\n",
    "O conjunto recebe colunas auxiliares (ano, mês, dia da semana) e medidas de comprimento textual. Essa engenharia de atributos facilita agregações temporais e a filtragem de discursos com tamanho inadequado para análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ba0d99",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "id": "98ba0d99",
    "outputId": "86ec0d90-7863-4cd6-b03c-2503539f91dd"
   },
   "outputs": [],
   "source": [
    "df = df_raw.copy()\n",
    "\n",
    "df['ano'] = df['Data'].dt.year\n",
    "# Representacao mensal padronizada\n",
    "mes_periodo = df['Data'].dt.to_period('M')\n",
    "df['mes'] = mes_periodo.dt.to_timestamp()\n",
    "\n",
    "dias_semana_pt = {\n",
    "    0: 'Segunda',\n",
    "    1: 'Terca',\n",
    "    2: 'Quarta',\n",
    "    3: 'Quinta',\n",
    "    4: 'Sexta',\n",
    "    5: 'Sabado',\n",
    "    6: 'Domingo'\n",
    "}\n",
    "df['dia_semana'] = df['Data'].dt.dayofweek.map(dias_semana_pt)\n",
    "\n",
    "# Limpar e medir o texto integral\n",
    "texto_coluna = 'TextoDiscursoIntegral'\n",
    "df[texto_coluna] = df[texto_coluna].fillna('').str.strip()\n",
    "df['texto_len_palavras'] = df[texto_coluna].str.split().str.len()\n",
    "df['texto_len_caracteres'] = df[texto_coluna].str.len()\n",
    "\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462cc307",
   "metadata": {
    "id": "462cc307"
   },
   "source": [
    "### 2.7. Analisar a evolução temporal do número de discursos\n",
    "A série mensal de pronunciamentos revela sazonalidades legislativas, destacando picos em momentos de votações relevantes e reduções em períodos de recesso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09261df3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "id": "09261df3",
    "outputId": "a8aa1cf3-a24c-4733-8d7d-a5675b713faf"
   },
   "outputs": [],
   "source": [
    "discursos_por_mes = (\n",
    "    df.groupby('mes')\n",
    "      .size()\n",
    "      .reset_index(name='discursos')\n",
    "      .sort_values('mes')\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.lineplot(data=discursos_por_mes, x='mes', y='discursos', ax=ax, marker='o')\n",
    "ax.set(title='Discursos por mes', xlabel='Mes', ylabel='Quantidade de discursos')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb9fa08",
   "metadata": {
    "id": "6eb9fa08"
   },
   "source": [
    "### 2.8. Identificar os autores mais atuantes no plenário\n",
    "O ranqueamento de oradores evidencia senadores com maior presença na tribuna, permitindo relacionar protagonismo individual a pautas específicas da legislatura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52628f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 622
    },
    "id": "b52628f7",
    "outputId": "8b13d0ba-9fcc-484a-a86b-cfa7ca2ba656"
   },
   "outputs": [],
   "source": [
    "top_autores = (\n",
    "    df.groupby('NomeAutor')\n",
    "      .size()\n",
    "      .sort_values(ascending=False)\n",
    "      .head(10)\n",
    "      .reset_index(name='discursos')\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.barplot(data=top_autores, x='discursos', y='NomeAutor', palette='Blues_r', ax=ax)\n",
    "ax.set(title='Autores com maior numero de discursos', xlabel='Quantidade de discursos', ylabel='Autor')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2ceb77",
   "metadata": {
    "id": "2b2ceb77"
   },
   "source": [
    "### 2.9. Mapear os partidos com maior presença nos discursos\n",
    "O agrupamento por sigla confirma a predominância de partidos com bancadas amplas e atuação destacada. Essa leitura orienta a seleção de classes para o modelo supervisionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9318cd6a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 622
    },
    "id": "9318cd6a",
    "outputId": "f7d4332b-a824-477c-ffcd-b178adad963f"
   },
   "outputs": [],
   "source": [
    "top_partidos = (\n",
    "    df['Partido']\n",
    "      .replace('', np.nan)\n",
    "      .dropna()\n",
    "      .value_counts()\n",
    "      .head(10)\n",
    "      .rename_axis('Partido')\n",
    "      .reset_index(name='discursos')\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.barplot(data=top_partidos, x='discursos', y='Partido', palette='viridis', ax=ax)\n",
    "ax.set(title='Partidos com maior atuacao em plenario', xlabel='Quantidade de discursos', ylabel='Partido')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf936c4",
   "metadata": {
    "id": "7cf936c4"
   },
   "source": [
    "### 2.10. Comparar a intensidade anual de discursos dos partidos mais frequentes\n",
    "Filtram-se os partidos no topo do ranking e gera-se tabela dinâmica por ano, permitindo contrastar variações de engajamento legislativo ao longo do tempo entre essas siglas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e859fd27",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 556
    },
    "id": "e859fd27",
    "outputId": "5e9754cf-c72e-43c5-efa1-2103daba9d26"
   },
   "outputs": [],
   "source": [
    "heatmap_data = (\n",
    "    df[df['Partido'].isin(top_partidos['Partido'])]\n",
    "      .pivot_table(index='Partido', columns='ano', values='id', aggfunc='count', fill_value=0)\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(heatmap_data, annot=True, fmt='.0f', cmap='rocket_r', ax=ax)\n",
    "ax.set(title='Intensidade anual de discursos por partido', xlabel='Ano', ylabel='Partido')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9d19e8",
   "metadata": {
    "id": "ac9d19e8"
   },
   "source": [
    "### 2.11. Avaliar a distribuição do tamanho dos discursos em palavras\n",
    "Um histograma com 60 classes descreve a densidade do comprimento textual, destacando a cauda longa e a presença de pronunciamentos extensos que podem influenciar a vetorização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945a7ef6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "id": "945a7ef6",
    "outputId": "75829c25-c1c2-4541-80ff-f8ea284483f0"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.histplot(df['texto_len_palavras'], bins=60, ax=ax)\n",
    "ax.set(title='Distribuicao do tamanho dos discursos (palavras)', xlabel='Numero de palavras', ylabel='Frequencia')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5572f4",
   "metadata": {
    "id": "af5572f4"
   },
   "source": [
    "### 2.12. Comparar o comprimento dos discursos entre os partidos mais frequentes\n",
    "Boxplots para os partidos líderes expõem diferenças de mediana e dispersão no tamanho dos discursos, sinalizando estilos discursivos mais concisos ou prolixos por legenda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd58e8c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "id": "bbd58e8c",
    "outputId": "55e9cea9-e5de-4cc4-a224-e7f31ec1036a"
   },
   "outputs": [],
   "source": [
    "partidos_para_boxplot = top_partidos['Partido'].head(6).tolist()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.boxplot(\n",
    "    data=df[df['Partido'].isin(partidos_para_boxplot)],\n",
    "    x='Partido',\n",
    "    y='texto_len_palavras',\n",
    "    ax=ax\n",
    ")\n",
    "ax.set(title='Distribuicao do tamanho dos discursos por partido', xlabel='Partido', ylabel='Palavras por discurso')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91e5a24",
   "metadata": {
    "id": "a91e5a24"
   },
   "source": [
    "### 2.13. Quantificar discursos por ano\n",
    "A agregação anual mostra como o volume de pronunciamentos se distribui ao longo da legislatura, permitindo comparar períodos pré e pós-pandemia e anos eleitorais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c23b83f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 704
    },
    "id": "6c23b83f",
    "outputId": "e06fe43a-6cd8-4068-cfd2-8037f8a01d8a"
   },
   "outputs": [],
   "source": [
    "discursos_por_ano = (\n",
    "    df.dropna(subset=['ano'])\n",
    "      .groupby('ano')\n",
    "      .size()\n",
    "      .reset_index(name='discursos')\n",
    "      .sort_values('ano')\n",
    ")\n",
    "\n",
    "discursos_por_ano['ano'] = discursos_por_ano['ano'].astype(int)\n",
    "plot_discursos_por_ano = discursos_por_ano.assign(ano=discursos_por_ano['ano'].astype(str))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.barplot(data=plot_discursos_por_ano, x='ano', y='discursos', color='C0', ax=ax)\n",
    "ax.set(title='Discursos por ano', xlabel='Ano', ylabel='Quantidade de discursos')\n",
    "plt.tight_layout()\n",
    "\n",
    "discursos_por_ano\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591afc0e",
   "metadata": {
    "id": "591afc0e"
   },
   "source": [
    "### 2.14. Distribuição de discursos por dia da semana\n",
    "A contagem por dia da semana confirma o ritmo do plenário, concentrado em terças, quartas e quintas-feiras, em consonância com o calendário legislativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a4eb2d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 690
    },
    "id": "49a4eb2d",
    "outputId": "80b3b648-2719-4df6-dd7a-93cfc71ac4c6"
   },
   "outputs": [],
   "source": [
    "\n",
    "dias_semana_ordem = ['Segunda', 'Terça', 'Quarta', 'Quinta', 'Sexta']\n",
    "distribuicao_semana = (\n",
    "    df.dropna(subset=['dia_semana'])\n",
    "      .assign(dia_semana=lambda s: s['dia_semana'].replace({\n",
    "          'Terca': 'Terça', 'Quarta': 'Quarta', 'Quinta': 'Quinta',\n",
    "          'Sexta': 'Sexta', 'Sabado': 'Sábado', 'Domingo': 'Domingo'\n",
    "      }))\n",
    "      .groupby('dia_semana')\n",
    "      .size()\n",
    "      .reindex(dias_semana_ordem, fill_value=0)\n",
    "      .rename('discursos')\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "sns.barplot(data=distribuicao_semana, x='dia_semana', y='discursos', color='C0', ax=ax)\n",
    "ax.set(title='Distribuição de discursos por dia da semana', xlabel='Dia da semana', ylabel='Quantidade de discursos')\n",
    "plt.tight_layout()\n",
    "\n",
    "distribuicao_semana\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f76dbc",
   "metadata": {
    "id": "59f76dbc"
   },
   "source": [
    "### 2.15. Estados com mais discursos registrados\n",
    "A agregação por unidade da federação identifica quais representações estaduais utilizam mais a tribuna, trazendo à tona lideranças regionais e eventuais desequilíbrios de participação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27d6cb9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 947
    },
    "id": "f27d6cb9",
    "outputId": "48431dad-84f9-4682-fbfc-8192f5d1b66f"
   },
   "outputs": [],
   "source": [
    "\n",
    "discursos_por_uf = (\n",
    "    df['UF']\n",
    "      .replace('', 'Não informado')\n",
    "      .value_counts()\n",
    "      .head(10)\n",
    "      .rename('discursos')\n",
    "      .reset_index()\n",
    "      .rename(columns={'index': 'UF'})\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.barplot(data=discursos_por_uf, x='discursos', y='UF', color='C1', ax=ax)\n",
    "ax.set(title='Estados com mais discursos registrados', xlabel='Quantidade de discursos', ylabel='UF')\n",
    "plt.tight_layout()\n",
    "\n",
    "discursos_por_uf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ab4246",
   "metadata": {
    "id": "68ab4246"
   },
   "source": [
    "### 2.16. Principais tipos de uso da palavra\n",
    "A coluna de tipo de uso diferencia comunicações, apartes e demais atos regimentais. Mapear sua frequência mostra o perfil predominante de intervenção no plenário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554a7c64",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 861
    },
    "id": "554a7c64",
    "outputId": "83c7b8c6-3bd1-428f-ed3d-faa76bc5bbb8"
   },
   "outputs": [],
   "source": [
    "tipo_uso_palavra = (\n",
    "    df['TipoUsoPalavra.Descricao']\n",
    "      .fillna('Não informado')\n",
    "      .replace('', 'Não informado')\n",
    "      .value_counts()\n",
    "      .head(10)\n",
    "      .rename('discursos')\n",
    "      .reset_index()\n",
    "      .rename(columns={'index': 'Tipo de uso'})\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.barplot(data=tipo_uso_palavra, x='discursos', y='TipoUsoPalavra.Descricao', color='C2', ax=ax)\n",
    "ax.set(title='Principais tipos de uso da palavra', xlabel='Quantidade de discursos', ylabel='')\n",
    "plt.tight_layout()\n",
    "\n",
    "tipo_uso_palavra\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5642570d",
   "metadata": {
    "id": "5642570d"
   },
   "source": [
    "### 2.17. Preparar colunas textuais para inspeção\n",
    "As variáveis textuais são normalizadas para strings vazias em casos de ausência, prevenindo falhas em operações posteriores e mantendo consistência na limpeza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271278e4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "271278e4",
    "outputId": "da34e748-d6f6-4dd4-b418-ee316677bb22"
   },
   "outputs": [],
   "source": [
    "\n",
    "colunas_textuais = [\n",
    "    'Resumo', 'Indexacao', 'TextoIntegral', 'TextoIntegralTxt',\n",
    "    'TextoDiscursoIntegral', 'TipoUsoPalavra.Descricao', 'TipoUsoPalavra.Sigla',\n",
    "    'TipoUsoPalavra.Codigo', 'TipoUsoPalavra.IndicadorAtivo',\n",
    "    'Publicacoes.Publicacao', 'Apartes.Aparteante', 'CargoAutor',\n",
    "    'OrgaoAutor', 'PaisAutor'\n",
    "]\n",
    "\n",
    "for coluna in colunas_textuais:\n",
    "    if coluna in df.columns:\n",
    "        df[coluna] = df[coluna].fillna('').astype(str)\n",
    "\n",
    "qtd_sem_texto = (df['TextoDiscursoIntegral'].str.strip() == '').sum()\n",
    "print(f'Discursos sem texto integral disponível: {qtd_sem_texto}')\n",
    "\n",
    "preview_sem_texto = df[df['TextoDiscursoIntegral'].str.strip() == ''][['id', 'NomeAutor', 'Data']].head()\n",
    "preview_sem_texto\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67cc106",
   "metadata": {
    "id": "c67cc106"
   },
   "source": [
    "### 2.18. Medir palavras e caracteres por discurso\n",
    "Indicadores de comprimento para textos integrais e resumos ajudam a detectar outliers de tamanho e servem de base para filtros mínimos de qualidade textual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b459139",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "6b459139",
    "outputId": "d234a775-03af-4344-c149-2ffc1e94ec87"
   },
   "outputs": [],
   "source": [
    "\n",
    "df['texto_len_palavras'] = df['TextoDiscursoIntegral'].str.split().str.len()\n",
    "df['texto_len_caracteres'] = df['TextoDiscursoIntegral'].str.len()\n",
    "df['resumo_len_palavras'] = df['Resumo'].str.split().str.len()\n",
    "\n",
    "df[['id', 'texto_len_palavras', 'texto_len_caracteres', 'resumo_len_palavras']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80da51e",
   "metadata": {
    "id": "d80da51e"
   },
   "source": [
    "### 2.19. Estatísticas descritivas do tamanho dos discursos\n",
    "Resumo de estatísticas (mediana, quartis e amplitude) reforça a heterogeneidade do corpus e auxilia na escolha de cortes de tamanho para a modelagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ad4dfb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "a1ad4dfb",
    "outputId": "707fb0e9-1b79-41ad-a544-49104325be56"
   },
   "outputs": [],
   "source": [
    "\n",
    "tamanho_discursos = pd.DataFrame({\n",
    "    'palavras': df['texto_len_palavras'].describe().round(2),\n",
    "    'caracteres': df['texto_len_caracteres'].describe().round(2)\n",
    "})\n",
    "\n",
    "tamanho_discursos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86a37be",
   "metadata": {
    "id": "d86a37be"
   },
   "source": [
    "### 2.20. Nuvem de palavras dos discursos\n",
    "A nuvem de palavras sintetiza o vocabulário dominante, excluindo termos genéricos por meio de uma lista ampliada de stopwords em português, de modo a ressaltar temas substantivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1517a197",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 548
    },
    "id": "1517a197",
    "outputId": "7d0c3373-2595-4e36-e5d3-e51df11382f9"
   },
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    from wordcloud import WordCloud\n",
    "    import nltk\n",
    "    from nltk.corpus import stopwords as nltk_stopwords\n",
    "except ImportError as err:\n",
    "    print('Bibliotecas opcionais ausentes. Instale `wordcloud` e `nltk` para gerar a nuvem de palavras.')\n",
    "else:\n",
    "    try:\n",
    "        nltk.data.find('corpora/stopwords')\n",
    "    except LookupError:\n",
    "        try:\n",
    "            nltk.download('stopwords', quiet=True)\n",
    "        except Exception as download_err:\n",
    "            print('Não foi possível baixar as stopwords do NLTK:', download_err)\n",
    "    try:\n",
    "        stopwords_pt = set(nltk_stopwords.words('portuguese'))\n",
    "    except LookupError:\n",
    "        stopwords_pt = set()\n",
    "    stopwords_extra = {\n",
    "        'senhor', 'senhora', 'senhores', 'senhoras', 'presidente', 'presidência',\n",
    "        'senado', 'federal', 'brasil', 'brasileiros', 'brasileiras', 'palavra',\n",
    "        'sessão', 'ordem', 'anos', 'ano', 'quero', 'fazer', 'feito', 'gente',\n",
    "        'nosso', 'nossa', 'nossos', 'nossas', 'dizer', 'diz', 'fez', 'governo',\n",
    "        'nacional', 'discurso', 'então', 'sr', 'pode', 'aqui', 'grande', 'pessoa', 'todo',\n",
    "        'hoje', 'dia', 'dessa', 'lá', 'exmo', 'vai', 'porque', 'agora', 'ainda',\n",
    "        'sempre', 'sobre', 'vamos', 'ter', 'bem', 'outra', 'muita', 'muitas', 'certeza',\n",
    "        'apenas', 'caso', 'ontem', 'sim', 'desde', 'realmente', 'aí', 'sra',\n",
    "        'todas', 'dias', 'amigo', 'tudo', 'outras', 'vez', 'número', 'vou', 'fala',\n",
    "        'precisa', 'possa', 'sabe', 'neste', 'junto', 'art', 'assim', 'maior', 'mil',\n",
    "        'alguma', 'falando', 'portanto', 'dentro', 'fato', 'desta', 'nessa', 'nesse',\n",
    "        'onde', 'nova', 'quanto', 'disso', 'srs', 'ali', 'bom', 'coisa', 'outros',\n",
    "        'vezes', 'tanto', 'deste', 'nesta', 'têm', 'cada', 'faz', 'sendo', 'boa',\n",
    "        'menos', 'último', 'vão', 'meio', 'nada', 'dado', 'quase', 'gostaria',\n",
    "        'importância', 'alguns', 'ponto', 'qualquer', 'pois', 'sentido', 'vem', 'tão',\n",
    "        'dá', 'partir', 'contra', 'dar', 'sei', 'melhor', 'nunca', 'através', 'deixar',\n",
    "        'obrigado', 'obrigada', 'acho', 'nenhum', 'exemplo', 'mínimo', 'lado', 'muitos', 'falar'\n",
    "    }\n",
    "    stopwords = stopwords_pt.union(stopwords_extra)\n",
    "\n",
    "    textos = df['TextoDiscursoIntegral'].dropna()\n",
    "    textos = textos[textos.str.len() > 0]\n",
    "\n",
    "    if textos.empty:\n",
    "        print('Não há textos integrais disponíveis para gerar a nuvem de palavras.')\n",
    "    else:\n",
    "        corpus = ' '.join(textos.values)\n",
    "        wordcloud = WordCloud(\n",
    "            width=960,\n",
    "            height=480,\n",
    "            background_color='white',\n",
    "            max_words=200,\n",
    "            collocations=False,\n",
    "            stopwords=stopwords\n",
    "        ).generate(corpus)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(14, 7))\n",
    "        ax.imshow(wordcloud, interpolation='bilinear')\n",
    "        ax.axis('off')\n",
    "        ax.set_title('Nuvem de palavras dos discursos do Senado', fontsize=14)\n",
    "        plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d83165",
   "metadata": {
    "id": "c1d83165"
   },
   "source": [
    "### 2.21. Principais achados da análise descritiva\n",
    "O corpus apresenta concentração de discursos entre 2019 e 2022, com retomada vigorosa após a fase aguda da pandemia e protagonismo de partidos como PT, Podemos e MDB. A distribuição semanal confirma terça a quinta-feira como eixo da atividade, e as análises por autor e UF evidenciam lideranças regionais. O tamanho mediano de aproximadamente 460 palavras, aliado à dispersão elevada, sugere a necessidade de vetorização que lide bem com documentos de extensão variável."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fe2c69",
   "metadata": {
    "id": "a7fe2c69"
   },
   "source": [
    "## 3. Divisão dos Dados\n",
    "A tarefa supervisionada consiste em classificar o partido com base no texto integral. O DataFrame é filtrado para manter pronunciamentos válidos, assegurar presença de rótulo e delimitar o conjunto a classes com representatividade suficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9070e414",
   "metadata": {
    "id": "9070e414"
   },
   "source": [
    "### 3.1. Construir uma base textualmente limpa e pronta para modelagem\n",
    "Selecionaram-se colunas relevantes, removeram-se registros incompletos, aplicou-se limpeza para eliminar dígitos e pontuação e filtraram-se discursos com menos de 20 palavras. A análise foi limitada aos oito partidos mais frequentes; do texto foram removidas referências explícitas ao autor, ao partido e à UF para mitigar vazamento antes da vetorização."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Bprt0HFQ-fxU",
   "metadata": {
    "id": "Bprt0HFQ-fxU"
   },
   "source": [
    "A escolha dos oito partidos (DEM, MDB, PL, PODEMOS, PP, PSD, PSDB, PT) reflete a intenção de focar em classes com volume suficiente para treino e avaliação equilibrados, evitando distorções de métricas por baixa representatividade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3064e233",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "3064e233",
    "outputId": "6ccc7c31-f552-40f6-f124-b425d85288d8"
   },
   "outputs": [],
   "source": [
    "colunas_modelo = ['Partido', 'UF', 'NomeAutor', 'Data', 'TextoDiscursoIntegral']\n",
    "\n",
    "def limpar_texto_basico(texto: str) -> str:\n",
    "    \"\"\"Normaliza texto em minúsculas e remove ruídos básicos.\"\"\"\n",
    "    texto = texto.lower()\n",
    "    texto = re.sub(r'\\d+', ' ', texto)\n",
    "    texto = re.sub(r'[^\\w\\s]', ' ', texto)\n",
    "    texto = re.sub(r'\\s+', ' ', texto).strip()\n",
    "    return texto\n",
    "\n",
    "base_modelo = (\n",
    "    df[colunas_modelo]\n",
    "      .dropna(subset=['Partido', 'TextoDiscursoIntegral'])\n",
    "      .copy()\n",
    ")\n",
    "\n",
    "base_modelo['texto'] = base_modelo['TextoDiscursoIntegral'].str.strip()\n",
    "base_modelo = base_modelo[base_modelo['texto'].str.len() > 0]\n",
    "base_modelo['n_palavras'] = base_modelo['texto'].str.split().str.len()\n",
    "base_modelo = base_modelo[base_modelo['n_palavras'] >= 20]\n",
    "\n",
    "partidos_selecionados = base_modelo['Partido'].value_counts().head(8).index.tolist()\n",
    "base_modelo = base_modelo[base_modelo['Partido'].isin(partidos_selecionados)].copy()\n",
    "\n",
    "# Remove padrões que vazam a resposta (siglas partidárias, UF e o nome completo do autor)\n",
    "partidos_lista = sorted(base_modelo['Partido'].dropna().str.lower().unique().tolist())\n",
    "ufs_lista = sorted(base_modelo['UF'].dropna().str.lower().unique().tolist())\n",
    "regex_partidos = re.compile(r'\\b(' + '|'.join(map(re.escape, partidos_lista)) + r')\\b') if partidos_lista else None\n",
    "regex_ufs = re.compile(r'\\b(' + '|'.join(map(re.escape, ufs_lista)) + r')\\b') if ufs_lista else None\n",
    "\n",
    "def remover_referencias(texto: str, autor: str, partido: str, uf: str) -> str:\n",
    "    texto = limpar_texto_basico(texto)\n",
    "    if autor:\n",
    "        texto = re.sub(re.escape(str(autor).lower()), ' ', texto)\n",
    "        for token in str(autor).lower().split():\n",
    "            texto = re.sub(rf'\\b{re.escape(token)}\\b', ' ', texto)\n",
    "    if regex_partidos:\n",
    "        texto = regex_partidos.sub(' ', texto)\n",
    "    if regex_ufs:\n",
    "        texto = regex_ufs.sub(' ', texto)\n",
    "    texto = re.sub(r'\\s+', ' ', texto).strip()\n",
    "    return texto\n",
    "\n",
    "base_modelo['texto_limpo'] = base_modelo.apply(\n",
    "    lambda row: remover_referencias(row['texto'], row['NomeAutor'], row['Partido'], row['UF']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "base_modelo[['Partido', 'UF', 'NomeAutor', 'n_palavras', 'texto_limpo']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6352ee",
   "metadata": {
    "id": "9a6352ee"
   },
   "source": [
    "### 3.2 Verificar a distribuição final de amostras por partido após o balanceamento\n",
    "A distribuição por classe é revisada para confirmar o efeito dos filtros e subsidiar decisões de balanceamento controlado no conjunto de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6db812",
   "metadata": {},
   "outputs": [],
   "source": [
    "distribuicao_filtrada = base_modelo['Partido'].value_counts().to_frame('total_pos_filtro')\n",
    "distribuicao_filtrada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080bdab6",
   "metadata": {
    "id": "080bdab6"
   },
   "source": [
    "### 3.3 Separar os dados em conjuntos de treino e teste preservando a proporção entre classes\n",
    "A divisão estratificada em treino e teste mantém a proporção original de partidos. Qualquer ajuste de balanceamento é aplicado apenas no treino, preservando a integridade do teste para medir desempenho realista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52e53b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b52e53b6",
    "outputId": "6e92b204-0062-4d17-aa18-20147fd1a4da"
   },
   "outputs": [],
   "source": [
    "# Divide antes de balancear para evitar vazamento\n",
    "df_treino, df_teste = train_test_split(\n",
    "    base_modelo[['Partido', 'texto_limpo']],\n",
    "    test_size=0.2,\n",
    "    stratify=base_modelo['Partido'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "def undersample_por_partido(df_balancear, max_por_partido=800):\n",
    "    amostras = []\n",
    "    for partido, grupo in df_balancear.groupby('Partido'):\n",
    "        tamanho = min(len(grupo), max_por_partido)\n",
    "        amostras.append(grupo.sample(n=tamanho, random_state=42))\n",
    "    return pd.concat(amostras).reset_index(drop=True)\n",
    "\n",
    "df_treino_bal = undersample_por_partido(df_treino, max_por_partido=800)\n",
    "\n",
    "X_train = df_treino_bal['texto_limpo']\n",
    "y_train = df_treino_bal['Partido']\n",
    "\n",
    "X_test = df_teste['texto_limpo']\n",
    "y_test = df_teste['Partido']\n",
    "\n",
    "print(f'Amostras treino balanceadas: {len(X_train)} | Amostras teste (originais): {len(X_test)}')\n",
    "print('Distribuicao treino balanceado (top 5):')\n",
    "print(y_train.value_counts().head())\n",
    "\n",
    "distribuicao_partido = pd.DataFrame({\n",
    "    'treino_balanceado': y_train.value_counts().sort_index(),\n",
    "    'teste_original': y_test.value_counts().sort_index()\n",
    "})\n",
    "distribuicao_partido"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fmZAkjnu6lk9",
   "metadata": {
    "id": "fmZAkjnu6lk9"
   },
   "source": [
    "### Prevenção de vazamento de rótulo\n",
    "As etapas de pré-processamento removem menções diretas ao partido, à UF e ao nome do orador antes da vetorização. O balanceamento ocorre somente após o `train_test_split`, garantindo que o conjunto de teste permaneça isolado de decisões tomadas no treino."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012c0f60",
   "metadata": {
    "id": "012c0f60"
   },
   "source": [
    "## 4. Pré-processamento dos Dados\n",
    "O pipeline supervisionado emprega vetorização TF-IDF em n-gramas (1 a 2) para capturar padrões lexicais relevantes. A limpeza textual preserva acentuação e elimina ruídos, equilibrando custo computacional e riqueza semântica para o português."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46116d83",
   "metadata": {
    "id": "46116d83"
   },
   "source": [
    "## 5. Construção e Escolha do Modelo\n",
    "Quatro classificadores lineares são avaliados com a mesma representação TF-IDF: Regressão Logística, SVM linear, Multinomial Naive Bayes e Passive Aggressive. As métricas centrais são acurácia e F1 macro, priorizando equilíbrio entre classes com suportes distintos. Essa trilha supervisionada será posteriormente contraposta ao diagnóstico temático obtido via NMF para checar se a separação por partido se apoia em diferenças substantivas de agenda."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5fec43",
   "metadata": {
    "id": "ba5fec43"
   },
   "source": [
    "### 5.1 Comparar diferentes algoritmos lineares para o problema de classificação de partido\n",
    "Pipelines que combinam TF-IDF e cada classificador são treinados e comparados. As previsões sobre o conjunto de teste alimentam uma tabela de métricas que guia a escolha do modelo mais adequado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fc31f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "57fc31f4",
    "outputId": "21d2d899-3596-4d6b-ec88-477003bcdd09"
   },
   "outputs": [],
   "source": [
    "modelos = [\n",
    "    ('Regressao Logistica', LogisticRegression(max_iter=1000, solver='lbfgs', random_state=42)),\n",
    "    ('SVM Linear', LinearSVC(random_state=42)),\n",
    "    ('Naive Bayes', MultinomialNB()),\n",
    "    ('Passive Aggressive', PassiveAggressiveClassifier(max_iter=1000, random_state=42, tol=1e-3))\n",
    "]\n",
    "\n",
    "resultados_modelos = []\n",
    "\n",
    "for nome, estimador in modelos:\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(\n",
    "            max_features=20000,\n",
    "            ngram_range=(1, 2),\n",
    "            min_df=5,\n",
    "            strip_accents='unicode'\n",
    "        )),\n",
    "        ('clf', estimador)\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    resultados_modelos.append({\n",
    "        'modelo': nome,\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'f1_macro': f1_score(y_test, y_pred, average='macro'),\n",
    "        'f1_weighted': f1_score(y_test, y_pred, average='weighted')\n",
    "    })\n",
    "\n",
    "resultados_df = pd.DataFrame(resultados_modelos).sort_values('f1_macro', ascending=False).reset_index(drop=True)\n",
    "resultados_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658d4fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "melhor = resultados_df.iloc[0]\n",
    "segundo = resultados_df.iloc[1]\n",
    "print(f\"Melhor desempenho: {melhor['modelo']} (F1 macro={melhor['f1_macro']:.3f}, acc={melhor['accuracy']:.3f}).\")\n",
    "print(f\"Segundo lugar: {segundo['modelo']} (F1 macro={segundo['f1_macro']:.3f}).\")\n",
    "delta = melhor['f1_macro'] - segundo['f1_macro']\n",
    "if abs(delta) < 0.01:\n",
    "    print('Diferença marginal: modelos são equivalentes; preferir o mais interpretável.')\n",
    "elif delta > 0:\n",
    "    print('Melhor modelo tem vantagem clara em equilíbrio entre classes (f1_macro).')\n",
    "else:\n",
    "    print('Apesar do f1_macro menor, considere robustez de outro modelo.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bc462e",
   "metadata": {},
   "source": [
    "**Leitura das métricas:** a comparação destaca o modelo com maior `f1_macro` como referência de equilíbrio entre classes. Diferenças grandes entre `accuracy` e `f1_macro` sinalizam sensibilidade a classes desequilibradas; valores próximos indicam estabilidade. O `f1_weighted` complementa evidenciando o impacto do suporte de cada partido."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe64dde",
   "metadata": {
    "id": "afe64dde"
   },
   "source": [
    "## 6. Otimização de hiperparâmetros\n",
    "Embora SVM linear e Passive Aggressive apresentem F1 macro elevado na comparação inicial, a Regressão Logística foi escolhida para refinamento por fornecer coeficientes interpretáveis. A busca em grade (k=3) varia parâmetros do TF-IDF e da regularização, buscando maximizar o F1 macro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00264469",
   "metadata": {
    "id": "00264469"
   },
   "source": [
    "### 6.1 Otimizar os hiperparâmetros do pipeline baseado em Regressão Logística\n",
    "Define-se um pipeline de base, especifica-se a grade de busca para frequência máxima de termos, intervalo de n-gramas e parâmetro `C`, e a validação cruzada estratificada identifica a configuração com melhor desempenho médio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561f57f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "561f57f6",
    "outputId": "bab6ae82-cb05-4140-d55d-156cb212004a"
   },
   "outputs": [],
   "source": [
    "pipeline_base = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        max_features=20000,\n",
    "        min_df=5,\n",
    "        strip_accents='unicode'\n",
    "    )),\n",
    "    ('clf', LogisticRegression(max_iter=1000, solver='lbfgs', random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'tfidf__max_df': [0.85, 0.95],\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "    'clf__C': [0.5, 1.0, 2.0],\n",
    "    'clf__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline_base,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_macro',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print('Melhores hiperparâmetros:')\n",
    "print(grid_search.best_params_)\n",
    "print(f'Melhor F1 macro (validacao): {grid_search.best_score_:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1ff339",
   "metadata": {
    "id": "de1ff339"
   },
   "source": [
    "## 7. Avaliação Final do Modelo\n",
    "Com os hiperparâmetros otimizados, o modelo supervisionado é aplicado ao conjunto de teste reservado. A avaliação inclui relatório de classificação, matriz de confusão e interpretação de termos, compondo um panorama da capacidade preditiva e da transparência do classificador. Esses achados são complementados, na seção de análise temática, por uma visão de tópicos que independe de rótulos e ajuda a validar se as distinções aprendidas refletem agendas reais."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab15e9de",
   "metadata": {
    "id": "ab15e9de"
   },
   "source": [
    "### 7.1. Medir o desempenho final do modelo otimizado no conjunto de teste\n",
    "O melhor estimador gera previsões no teste, e o `classification_report` é organizado em DataFrame para facilitar a leitura de precisão, revocação e F1 por partido e nas médias macro e ponderada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161cbdb4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "161cbdb4",
    "outputId": "89897a74-08d5-415f-8ad3-80f36628f7c1"
   },
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "report_dict = classification_report(y_test, y_pred_test, output_dict=True)\n",
    "relatorio_df = (\n",
    "    pd.DataFrame(report_dict)\n",
    "      .transpose()\n",
    "      .round(3)\n",
    ")\n",
    "relatorio_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f51ee04",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_f1 = relatorio_df.loc['macro avg', 'f1-score']\n",
    "weighted_f1 = relatorio_df.loc['weighted avg', 'f1-score']\n",
    "print(f'F1-macro (equilibrado): {macro_f1:.3f} | F1-weighted (ajustado ao suporte): {weighted_f1:.3f}')\n",
    "pior_partido = relatorio_df.drop(['accuracy', 'macro avg', 'weighted avg']).sort_values('f1-score').index[0]\n",
    "melhor_partido = relatorio_df.drop(['accuracy', 'macro avg', 'weighted avg']).sort_values('f1-score').index[-1]\n",
    "print(f'Partido com maior dificuldade: {pior_partido}. Melhor desempenho: {melhor_partido}.')\n",
    "print('Quando macro e weighted são próximos, o modelo distribui performance de forma homogênea entre partidos.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7c1cd3",
   "metadata": {},
   "source": [
    "A interpretação do relatório final se apoia em `recall` para localizar partidos com maior incidência de falsos negativos e em `precision` para identificar confusões com outras siglas. As médias macro e ponderada sintetizam o equilíbrio geral; a proximidade entre elas indica distribuição homogênea de desempenho, tornando a acurácia mais confiável como métrica global."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bd9974",
   "metadata": {
    "id": "a6bd9974"
   },
   "source": [
    "### 7.2. Visualizar acertos e erros do modelo entre as classes\n",
    "A matriz de confusão apresenta, em formato visual, o padrão de acertos e confusões entre partidos, ressaltando relações de proximidade temática implícitas nas confusões observadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5311f996",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 601
    },
    "id": "5311f996",
    "outputId": "0744ecdb-834b-4e6f-f490-9eb348761b0b"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_test, labels=best_model.named_steps['clf'].classes_)\n",
    "fig, ax = plt.subplots()\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=best_model.named_steps['clf'].classes_).plot(ax=ax, cmap='Blues', xticks_rotation=45)\n",
    "ax.set(title='Matriz de confusao - modelo otimizado')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "io7FokSc7wHT",
   "metadata": {
    "id": "io7FokSc7wHT"
   },
   "source": [
    "A leitura da matriz de confusão considera a diagonal principal como região de acertos; valores elevados fora dessa diagonal revelam pares de partidos frequentemente confundidos, muitas vezes por afinidade temática. Quando uma classe acumula falsos negativos, ajustes de `class_weight` ou coleta adicional de exemplos podem mitigar o problema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17150634",
   "metadata": {
    "id": "17150634"
   },
   "source": [
    "### 7.3. Interpretar os termos que mais contribuem para cada partido na Regressão Logística\n",
    "Os coeficientes do classificador são ordenados para cada classe, destacando os termos com maior peso positivo e permitindo examinar se as decisões se baseiam em tópicos substantivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec7aa2e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 529
    },
    "id": "1ec7aa2e",
    "outputId": "98dd4e35-b35e-460f-aad5-5be643d2fc1b"
   },
   "outputs": [],
   "source": [
    "tfidf_vect = best_model.named_steps['tfidf']\n",
    "clf = best_model.named_steps['clf']\n",
    "feature_names = np.array(tfidf_vect.get_feature_names_out())\n",
    "\n",
    "palavras_por_partido = {}\n",
    "for classe, coeficientes in zip(clf.classes_, clf.coef_):\n",
    "    top_indices = np.argsort(coeficientes)[-12:][::-1]\n",
    "    palavras_por_partido[classe] = feature_names[top_indices]\n",
    "\n",
    "pd.DataFrame(palavras_por_partido)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503dca7d",
   "metadata": {},
   "source": [
    "### 7.4. Explicabilidade via valores SHAP\n",
    "Valores SHAP calculados sobre a representação TF-IDF oferecem visão complementar da importância dos termos no conjunto de teste, reforçando a interpretabilidade e a prestação de contas do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262a9857",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import shap\n",
    "except ImportError:\n",
    "    print('Instale a biblioteca shap para gerar as explicações: pip install shap')\n",
    "else:\n",
    "    tfidf_vect = best_model.named_steps['tfidf']\n",
    "    clf = best_model.named_steps['clf']\n",
    "    X_train_tfidf = tfidf_vect.transform(X_train)\n",
    "    background = shap.utils.sample(X_train_tfidf, 200, random_state=42)\n",
    "    explainer = shap.LinearExplainer(clf, background)\n",
    "\n",
    "    amostra_teste = X_test.sample(min(30, len(X_test)), random_state=42)\n",
    "    shap_values = explainer(tfidf_vect.transform(amostra_teste))\n",
    "    shap.summary_plot(\n",
    "        shap_values,\n",
    "        feature_names=tfidf_vect.get_feature_names_out(),\n",
    "        max_display=15,\n",
    "        show=False\n",
    "    )\n",
    "    plt.title('Impacto médio dos termos - SHAP (teste)')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2349ec2",
   "metadata": {},
   "source": [
    "## 8. Análise temática não supervisionada\n",
    "Para complementar a classificação supervisionada por partido, aplicamos um modelo não supervisionado de tópicos (NMF) sobre o corpus de discursos. O objetivo é identificar agendas dominantes sem depender de rótulos, reforçando o storytelling sobre a atuação legislativa e oferecendo uma camada adicional de accountability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8800db0c",
   "metadata": {},
   "source": [
    "### 8.1 Preparar amostra e texto para o modelo de tópicos\n",
    "Seleciona-se uma amostra aleatória do corpus para acelerar o ajuste, aplicando limpeza básica e remoção de menções explícitas a partido e UF. A vetorização usa TF-IDF com unigrama e bigrama, privilegiando termos informativos em português."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bb60c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Função de limpeza inspirada na etapa supervisionada\n",
    "partidos_lista = sorted(df['Partido'].dropna().str.lower().unique().tolist())\n",
    "ufs_lista = sorted(df['UF'].dropna().str.lower().unique().tolist())\n",
    "regex_partidos = re.compile(r'\\b(' + '|'.join(map(re.escape, partidos_lista)) + r')\\b') if partidos_lista else None\n",
    "regex_ufs = re.compile(r'\\b(' + '|'.join(map(re.escape, ufs_lista)) + r')\\b') if ufs_lista else None\n",
    "\n",
    "def limpar_texto_topicos(texto):\n",
    "    texto = str(texto).lower()\n",
    "    texto = re.sub(r'\\d+', ' ', texto)\n",
    "    texto = re.sub(r'[^\\w\\s]', ' ', texto)\n",
    "    if regex_partidos:\n",
    "        texto = regex_partidos.sub(' ', texto)\n",
    "    if regex_ufs:\n",
    "        texto = regex_ufs.sub(' ', texto)\n",
    "    texto = re.sub(r'\\s+', ' ', texto).strip()\n",
    "    return texto\n",
    "\n",
    "# Amostra para tornar o ajuste viável em notebook\n",
    "amostra = df[['Data', 'Partido', 'UF', 'TextoDiscursoIntegral']].dropna(subset=['TextoDiscursoIntegral']).copy()\n",
    "amostra = amostra[amostra['TextoDiscursoIntegral'].str.len() > 0]\n",
    "if len(amostra) > 5000:\n",
    "    amostra = amostra.sample(5000, random_state=42)\n",
    "\n",
    "amostra['texto_limpo'] = amostra['TextoDiscursoIntegral'].apply(limpar_texto_topicos)\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=15000,\n",
    "    min_df=5,\n",
    "    max_df=0.8,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words='portuguese'\n",
    ")\n",
    "X_tfidf = vectorizer.fit_transform(amostra['texto_limpo'])\n",
    "print(f'Amostra usada no NMF: {X_tfidf.shape[0]} discursos, {X_tfidf.shape[1]} termos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9003ae",
   "metadata": {},
   "source": [
    "### 8.2 Descobrir e nomear temas com NMF\n",
    "Um modelo NMF com oito componentes é ajustado para decompor a matriz TF-IDF. Os termos de maior peso em cada componente ajudam a interpretar os temas latentes (saúde, economia, infraestrutura, educação, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8adb4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics = 8\n",
    "nmf_model = NMF(n_components=n_topics, random_state=42, init='nndsvd')\n",
    "W = nmf_model.fit_transform(X_tfidf)\n",
    "H = nmf_model.components_\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "termos_por_tema = {}\n",
    "for i, comp in enumerate(H):\n",
    "    top_indices = comp.argsort()[-12:][::-1]\n",
    "    termos_por_tema[f'Tema_{i+1}'] = feature_names[top_indices]\n",
    "\n",
    "termos_por_tema_df = pd.DataFrame(termos_por_tema)\n",
    "termos_por_tema_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bf826d",
   "metadata": {},
   "source": [
    "### 8.3 Evolução temporal dos temas\n",
    "Cada discurso é associado ao tema dominante (maior peso em `W`). A distribuição mensal revela como os tópicos ganham ou perdem relevância ao longo da legislatura, permitindo relacioná-los a eventos públicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9470c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dominante = W.argmax(axis=1)\n",
    "amostra = amostra.assign(\n",
    "    tema_dominante=dominante,\n",
    "    mes=amostra['Data'].dt.to_period('M').dt.to_timestamp()\n",
    ")\n",
    "\n",
    "temas_long = (\n",
    "    amostra\n",
    "    .groupby(['mes', 'tema_dominante'])\n",
    "    .size()\n",
    "    .reset_index(name='qtd')\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=temas_long, x='mes', y='qtd', hue='tema_dominante', palette='tab10')\n",
    "plt.title('Evolução mensal dos temas (amostra)')\n",
    "plt.ylabel('Discursos por tema')\n",
    "plt.xlabel('Mês')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b542c48d",
   "metadata": {},
   "source": [
    "### 8.4 Distribuição de temas por partido\n",
    "A matriz partido × tema mostra o percentual de discursos de cada sigla em cada tópico, útil para verificar alinhamento entre agenda e atuação discursiva sem depender de rótulos na modelagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df99037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_partido = pd.crosstab(amostra['Partido'], amostra['tema_dominante'], normalize='index') * 100\n",
    "matriz_partido.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b165490",
   "metadata": {
    "id": "7b165490"
   },
   "source": [
    "## 9. Discussão Crítica\n",
    "O volume de discursos concentra-se entre 2020 e 2022, acompanhando momentos de crise sanitária e o ciclo eleitoral, o que sugere relação direta entre eventos críticos e maior uso da tribuna. Autores como Izalci Lucas e Randolfe Rodrigues assumem protagonismo, indicando figuras centrais na agenda legislativa. A extensão dos discursos apresenta grande variabilidade, e partidos do campo ideológico identificado como “centrão” compartilham vocabulário e temas com outras legendas, o que dificulta a separação automática. Ainda assim, o classificador produz desempenho elevado, mas a proximidade temática exige cautela ao interpretar diferenças sutis de precisão e revocação. A análise não supervisionada de tópicos reforça essa leitura ao mostrar agendas transversais (p. ex., saúde ou economia) que atravessam siglas, servindo de alerta para limites da atribuição partidária baseada apenas em texto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69caa73b",
   "metadata": {},
   "source": [
    "## 10. Accountability e Governança\n",
    "O classificador supervisionado pode subsidiar mecanismos de prestação de contas ao verificar coerência entre fala e agenda partidária; discrepâncias devem acionar investigação por jornalistas, conselhos de transparência ou controladorias internas. A modelagem temática não supervisionada adiciona uma camada de auditoria: temas que emergem com força em discursos de um partido, mas sem correspondência em sua plataforma, indicam desalinhamento narrativo. A utilização das duas abordagens precisa ser acompanhada de documentação e publicação aberta dos dados, do código e das métricas, assegurando reprodutibilidade e auditabilidade. Recomenda-se monitorar continuamente desempenho e vieses para que as ferramentas fortaleçam a governança democrática em vez de legitimar narrativas desinformadas."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0271d898dc3c4235b93f02dafc85e1c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3fe8b2046c894495aa974515446b6655",
      "placeholder": "​",
      "style": "IPY_MODEL_cd0a2fa550b248aa8350e2e8e9fef253",
      "value": "README.md: "
     }
    },
    "24e5652a74b94dee98bf8cfb52faeb61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "264806a8113143c29527a8108d9cc257": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "280c0bd307a7483f81b2185fd5030129": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ec4d6b50db8e46b8babd29b357a01797",
      "placeholder": "​",
      "style": "IPY_MODEL_7853efa4b62341899a06a3761ef9023e",
      "value": "data/full/discursos_2019-02-01_2023-01-3(…): 100%"
     }
    },
    "2df828b1f9134906805a996629fd9a2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2fbb89313111421b8902f32096366f4e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30c45db7907145979efbf70026105c7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "346cf8d5c77b48dea58972a88994e291": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_524829815b3740fb8c61d6e8d93359e3",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_24e5652a74b94dee98bf8cfb52faeb61",
      "value": 1
     }
    },
    "3c8fc0b18bb144d7a62e4c64fc2d3923": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "3fe8b2046c894495aa974515446b6655": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "524829815b3740fb8c61d6e8d93359e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "58304f3fa8494f2a823e61208e329273": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "639d539e4a9f4a849ba5048365b55755": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2fbb89313111421b8902f32096366f4e",
      "placeholder": "​",
      "style": "IPY_MODEL_98a891f7985a4e9fb0d56c113c19d114",
      "value": " 15729/0 [00:00&lt;00:00, 33023.45 examples/s]"
     }
    },
    "7853efa4b62341899a06a3761ef9023e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "858619a3f38e42a8ace6b6b01c42ce3e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85f3deae3b6347dfa34e8cd82bd5c4ea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b51a3c5b2244e09957a5b5956d804d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "90541510d574459c80671b154196a604": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_264806a8113143c29527a8108d9cc257",
      "max": 27271035,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_30c45db7907145979efbf70026105c7a",
      "value": 27271035
     }
    },
    "98a891f7985a4e9fb0d56c113c19d114": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b5891155ff434ba5a0826ae93e0ee6e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0271d898dc3c4235b93f02dafc85e1c6",
       "IPY_MODEL_e21606d7189b4df5bf13c5052f3fe14c",
       "IPY_MODEL_c832fdfca7a34576a6279afd8c2a27b9"
      ],
      "layout": "IPY_MODEL_858619a3f38e42a8ace6b6b01c42ce3e"
     }
    },
    "c04598c6eb514e5bb4c01988da8b29fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8b51a3c5b2244e09957a5b5956d804d2",
      "placeholder": "​",
      "style": "IPY_MODEL_ecff607df32f4967aad2f161fde623e1",
      "value": " 27.3M/27.3M [00:01&lt;00:00, 23.1MB/s]"
     }
    },
    "c832fdfca7a34576a6279afd8c2a27b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_85f3deae3b6347dfa34e8cd82bd5c4ea",
      "placeholder": "​",
      "style": "IPY_MODEL_f437d0829b434fbba82bf80a4a938584",
      "value": " 4.36k/? [00:00&lt;00:00, 80.6kB/s]"
     }
    },
    "cd0a2fa550b248aa8350e2e8e9fef253": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d7f9611ee05e4c2fabc8fa5facd805c3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8876e49403244e1bbd54decf12887c2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ddbfe45dc76d40cbac88a6a7c375c14e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e21b48a1f60040ff9a6c4376405b6c14",
       "IPY_MODEL_346cf8d5c77b48dea58972a88994e291",
       "IPY_MODEL_639d539e4a9f4a849ba5048365b55755"
      ],
      "layout": "IPY_MODEL_d8876e49403244e1bbd54decf12887c2"
     }
    },
    "e21606d7189b4df5bf13c5052f3fe14c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c8fc0b18bb144d7a62e4c64fc2d3923",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e97e3f6ef16344649b0d0504c96e01cb",
      "value": 1
     }
    },
    "e21b48a1f60040ff9a6c4376405b6c14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_58304f3fa8494f2a823e61208e329273",
      "placeholder": "​",
      "style": "IPY_MODEL_2df828b1f9134906805a996629fd9a2d",
      "value": "Generating train split: "
     }
    },
    "e97e3f6ef16344649b0d0504c96e01cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ec4d6b50db8e46b8babd29b357a01797": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ecff607df32f4967aad2f161fde623e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f437d0829b434fbba82bf80a4a938584": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f46cfa6f94414cdbb751dbd4f137a364": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_280c0bd307a7483f81b2185fd5030129",
       "IPY_MODEL_90541510d574459c80671b154196a604",
       "IPY_MODEL_c04598c6eb514e5bb4c01988da8b29fd"
      ],
      "layout": "IPY_MODEL_d7f9611ee05e4c2fabc8fa5facd805c3"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
