{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62a0a3d3",
   "metadata": {},
   "source": [
    "# Analisar discursos\n",
    "\n",
    "O objetivo desse notebook é analisar discursos disponíveis no diretório _data. Para preparar uma nova base, execute o notebook 01_preparar_base_discursos.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd08135",
   "metadata": {},
   "source": [
    "## Carregar dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a06086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DATA = Path(\"_data/discursos_2019-02-01_2023-01-31.parquet\")\n",
    "df = pd.read_parquet(DATA)\n",
    "\n",
    "df[\"Data\"] = pd.to_datetime(df[\"Data\"], errors=\"coerce\")\n",
    "df = df[df[\"ok\"].eq(True) & df[\"TextoDiscursoIntegral\"].notna() & df[\"TextoDiscursoIntegral\"].str.len().gt(0)]\n",
    "df[\"ano\"] = df[\"Data\"].dt.year\n",
    "df[\"mes\"] = df[\"Data\"].dt.to_period(\"M\").astype(str)  # ex.: '2019-03'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d50974",
   "metadata": {},
   "source": [
    "## Mapa de temas (tópicos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1bca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from unidecode import unidecode\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def normalize(s):\n",
    "    s = unidecode((s or \"\").lower())\n",
    "    s = re.sub(r\"[^a-z0-9áéíóúãõç\\s]\", \" \", s)  # simples; ajuste se quiser\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "df[\"texto_clean\"] = df[\"TextoDiscursoIntegral\"].apply(normalize)\n",
    "\n",
    "# embeddings (semântica)\n",
    "model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "emb = model.encode(df[\"texto_clean\"].tolist(), batch_size=64, show_progress_bar=True, normalize_embeddings=True)\n",
    "\n",
    "# clusterização\n",
    "k = 20  # ajuste depois de olhar coerência\n",
    "km = KMeans(n_clusters=k, n_init=10, random_state=42)\n",
    "df[\"topico\"] = km.fit_predict(emb)\n",
    "\n",
    "# palavras-chave por tópico via TF-IDF médio (c-TF-IDF simplificado)\n",
    "vec = TfidfVectorizer(ngram_range=(1,2), min_df=5, max_df=0.8)\n",
    "X = vec.fit_transform(df[\"texto_clean\"])\n",
    "vocab = np.array(vec.get_feature_names_out())\n",
    "\n",
    "def top_terms_for_topic(t, n=12):\n",
    "    idx = np.where(df[\"topico\"].values == t)[0]\n",
    "    if len(idx)==0: return []\n",
    "    mean_tfidf = X[idx].mean(axis=0).A1\n",
    "    return vocab[mean_tfidf.argsort()[::-1][:n]].tolist()\n",
    "\n",
    "termos = {t: top_terms_for_topic(t) for t in sorted(df[\"topico\"].unique())}\n",
    "pd.DataFrame({\"topico\": list(termos.keys()), \"termos\": list(termos.values())}).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a3a64b",
   "metadata": {},
   "source": [
    "### Detalhes de um Parlamentar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afc9f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "codigos_parlamentares = dataframe_senadores_lista_legislatura[\"/Servico/Parlamentares/Parlamentar/IdentificacaoParlamentar/CodigoParlamentar\"]\n",
    "\n",
    "#codigos_parlamentares\n",
    "\n",
    "urls_detalhe_senador = [base_url + f\"senador/{codigo_parlamentar}.csv\" for codigo_parlamentar in codigos_parlamentares]\n",
    "urls_detalhe_senador[0]\n",
    "csv_detalhes_senador = [f\"_data/senador_{codigo_parlamentar}.csv\" for codigo_parlamentar in codigos_parlamentares]\n",
    "csv_detalhes_senador[0]\n",
    "\n",
    "\n",
    "requests.get(urls_detalhe_senador[0], params, headers=headers, stream=True, timeout=60)\n",
    "\n",
    "for i in range(len(urls_detalhe_senador)):\n",
    "    with requests.get(urls_detalhe_senador[i], headers=headers, stream=True, timeout=60) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(csv_detalhes_senador[i], \"wb\") as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "    print(f\"Detalhes do Senador {urls_detalhe_senador[i]} gravado com sucesso em {csv_detalhes_senador[i]}\")\n",
    "\n",
    "#response = requests.get(url[0], headers=headers)\n",
    "\n",
    "#detalhe_parlamentar = response.json()\n",
    "#detalhe_parlamentar = detalhe_parlamentar[\"DetalheParlamentar\"][\"Parlamentar\"][\"IdentificacaoParlamentar\"]\n",
    "#detalhe_parlamentar = pd.json_normalize(detalhe_parlamentar, sep=\".\")\n",
    "\n",
    "#detalhes_parlamentares\n",
    "#detalhe_parlamentares = detalhe_parlamentar\n",
    "\n",
    "\n",
    "#detalhe_parlamentares.append(detalhe_parlamentar)\n",
    "\n",
    "#detalhe_parlamentares\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4d1390",
   "metadata": {},
   "source": [
    "## Entes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f23ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 5. Estatísticas descritivas\n",
    "# ================================\n",
    "print(\"Total de proposições:\", len(df))\n",
    "print(\"\\nResumo estatístico:\")\n",
    "print(df.describe(include=\"all\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c29cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 6. Visualizações iniciais\n",
    "# ================================\n",
    "\n",
    "# Quantidade de proposições por tipo\n",
    "df[\"siglaTipo\"].value_counts().plot(kind=\"bar\", figsize=(8,4))\n",
    "plt.title(\"Distribuição por Tipo de Proposição\")\n",
    "plt.xlabel(\"Tipo\")\n",
    "plt.ylabel(\"Quantidade\")\n",
    "plt.show()\n",
    "\n",
    "# Proposições por ano\n",
    "df[\"ano\"].value_counts().sort_index().plot(kind=\"line\", marker=\"o\", figsize=(8,4))\n",
    "plt.title(\"Proposições por Ano\")\n",
    "plt.xlabel(\"Ano\")\n",
    "plt.ylabel(\"Quantidade\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b752d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 7. Discussão preliminar (anotações)\n",
    "# ================================\n",
    "# - Identificar variáveis com dados ausentes.\n",
    "print(df.isna().sum())\n",
    "\n",
    "# - Refletir sobre possíveis problemas:\n",
    "#   * Situações pouco padronizadas.\n",
    "#   * Textos longos em 'ementa' -> análise qualitativa ou NLP.\n",
    "#   * Discrepâncias entre anos com muitas/ poucas proposições.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70486c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"_data/discursos_2019-01-01_2023-01-31.csv\", sep=\";\")\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
