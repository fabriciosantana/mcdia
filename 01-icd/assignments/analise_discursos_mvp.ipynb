{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4cb7fa5",
   "metadata": {},
   "source": [
    "# Análise de Discursos de Senadores da 56ª Legislatura (2019-2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e802fc7",
   "metadata": {},
   "source": [
    "\n",
    "Pipeline:\n",
    "1) Coleta (JSON): lista de senadores, discursos por período/senador e texto integral do pronunciamento.\n",
    "2) Limpeza e normalização.\n",
    "3) Representação (TF‑IDF e embeddings).\n",
    "4) Tópicos (clusterização + c-TF-IDF) e Sentimento (baseline).\n",
    "5) Sumarização com RAG (esqueleto com citações).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "837c0081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (2.32.4)\n",
      "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.12/site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.12/site-packages (2.3.1)\n",
      "Requirement already satisfied: scikit-learn in /home/codespace/.local/lib/python3.12/site-packages (1.7.0)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.1.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting umap-learn\n",
      "  Downloading umap_learn-0.5.9.post2-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting hdbscan\n",
      "  Downloading hdbscan-0.8.40.tar.gz (6.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting bertopic\n",
      "  Downloading bertopic-0.17.3-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting unidecode\n",
      "  Downloading Unidecode-1.4.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/codespace/.local/lib/python3.12/site-packages (4.13.4)\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-6.1.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests) (2025.7.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Collecting click (from nltk)\n",
      "  Downloading click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2025.9.18-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Collecting tqdm (from nltk)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.56.2-py3-none-any.whl.metadata (40 kB)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/codespace/.local/lib/python3.12/site-packages (from sentence-transformers) (2.7.1+cpu)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.35.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: Pillow in /home/codespace/.local/lib/python3.12/site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from sentence-transformers) (4.14.1)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
      "Collecting numba>=0.51.2 (from umap-learn)\n",
      "  Downloading numba-0.62.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
      "Collecting pynndescent>=0.5 (from umap-learn)\n",
      "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: plotly>=4.7.0 in /home/codespace/.local/lib/python3.12/site-packages (from bertopic) (6.2.0)\n",
      "Collecting llvmlite>0.36.0 (from bertopic)\n",
      "  Downloading llvmlite-0.45.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/codespace/.local/lib/python3.12/site-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /home/codespace/.local/lib/python3.12/site-packages (from plotly>=4.7.0->bertopic) (1.46.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentence_transformers-5.1.1-py3-none-any.whl (486 kB)\n",
      "Downloading transformers-4.56.2-py3-none-any.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.35.0-py3-none-any.whl (563 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m563.4/563.4 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading umap_learn-0.5.9.post2-py3-none-any.whl (90 kB)\n",
      "Downloading bertopic-0.17.3-py3-none-any.whl (153 kB)\n",
      "Downloading Unidecode-1.4.0-py3-none-any.whl (235 kB)\n",
      "Downloading pypdf-6.1.0-py3-none-any.whl (322 kB)\n",
      "Downloading llvmlite-0.45.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numba-0.62.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
      "Downloading regex-2025.9.18-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (802 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.0/802.0 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Building wheels for collected packages: hdbscan\n",
      "  Building wheel for hdbscan (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for hdbscan: filename=hdbscan-0.8.40-cp312-cp312-linux_x86_64.whl size=4587717 sha256=81c18d229b1754c472f38e651268e0e559bd515902cc27a4efea66c3ad019b50\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/80/e7/bb/173ca0d8ce12718c4b5e6e01619c99653579b56969b97604b2\n",
      "Successfully built hdbscan\n",
      "Installing collected packages: unidecode, tqdm, safetensors, regex, pypdf, llvmlite, hf-xet, click, numba, nltk, huggingface-hub, tokenizers, pynndescent, hdbscan, umap-learn, transformers, sentence-transformers, bertopic\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/18\u001b[0m [unidecode]\u001b[33m  WARNING: The script unidecode is installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/18\u001b[0m [unidecode]\u001b[33m  WARNING: The script tqdm is installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/18\u001b[0m [nltk]\u001b[33m  WARNING: The script nltk is installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/18\u001b[0m [huggingface-hub]\u001b[33m  WARNING: The scripts hf, huggingface-cli and tiny-agents are installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m15/18\u001b[0m [transformers]\u001b[33m  WARNING: The scripts transformers and transformers-cli are installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/18\u001b[0m [bertopic]/18\u001b[0m [bertopic]transformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed bertopic-0.17.3 click-8.3.0 hdbscan-0.8.40 hf-xet-1.1.10 huggingface-hub-0.35.0 llvmlite-0.45.0 nltk-3.9.1 numba-0.62.0 pynndescent-0.5.13 pypdf-6.1.0 regex-2025.9.18 safetensors-0.6.2 sentence-transformers-5.1.1 tokenizers-0.22.1 tqdm-4.67.1 transformers-4.56.2 umap-learn-0.5.9.post2 unidecode-1.4.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Dependências (descomente se precisar instalar)\n",
    "%pip install requests pandas numpy scikit-learn nltk sentence-transformers umap-learn hdbscan bertopic unidecode beautifulsoup4 pypdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff3ddabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, re, time, datetime as dt\n",
    "from typing import List, Dict, Any, Iterable\n",
    "import requests, pandas as pd, numpy as np\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "\n",
    "BASE = \"https://legis.senado.leg.br/dadosabertos/\"\n",
    "OUT_DIR = \"_data\"; TEXT_DIR = \"_textos\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True); os.makedirs(TEXT_DIR, exist_ok=True)\n",
    "\n",
    "def make_session() -> requests.Session:\n",
    "    s = requests.Session()\n",
    "    retries = Retry(total=8, backoff_factor=0.6, status_forcelist=[429,500,502,503,504], allowed_methods=[\"GET\"])\n",
    "    s.mount(\"https://\", HTTPAdapter(max_retries=retries))\n",
    "    s.headers.update({\"Accept\": \"application/json\"})\n",
    "    return s\n",
    "\n",
    "sess = make_session()\n",
    "\n",
    "def yyyymmdd(d: dt.date) -> str: return d.strftime(\"%Y%m%d\")\n",
    "def make_windows(start: dt.date, end: dt.date, days_per_window: int = 31):\n",
    "    cur = start; one = dt.timedelta(days=1)\n",
    "    while cur <= end:\n",
    "        w_end = min(cur + dt.timedelta(days=days_per_window - 1), end)\n",
    "        yield (cur, w_end); cur = w_end + one\n",
    "\n",
    "def safe_root_dict(j: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    for k, v in j.items():\n",
    "        if isinstance(v, dict): return v\n",
    "    return j\n",
    "\n",
    "def extract_pronunciamentos(obj: Any) -> List[Dict[str, Any]]:\n",
    "    out = []\n",
    "    def rec(x):\n",
    "        if isinstance(x, dict):\n",
    "            for k, v in x.items():\n",
    "                if isinstance(k,str) and k.lower()==\"pronunciamento\" and isinstance(v, list): out.extend(v)\n",
    "                else: rec(v)\n",
    "        elif isinstance(x, list):\n",
    "            for it in x: rec(it)\n",
    "    rec(obj); return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "420181b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CodigoParlamentar</th>\n",
       "      <th>IdentificacaoParlamentar.NomeParlamentar</th>\n",
       "      <th>IdentificacaoParlamentar.NomeCompletoParlamentar</th>\n",
       "      <th>IdentificacaoParlamentar.SexoParlamentar</th>\n",
       "      <th>IdentificacaoParlamentar.FormaTratamento</th>\n",
       "      <th>IdentificacaoParlamentar.SiglaPartidoParlamentar</th>\n",
       "      <th>Mandatos.Mandato</th>\n",
       "      <th>IdentificacaoParlamentar.CodigoPublicoNaLegAtual</th>\n",
       "      <th>IdentificacaoParlamentar.UrlFotoParlamentar</th>\n",
       "      <th>IdentificacaoParlamentar.UrlPaginaParlamentar</th>\n",
       "      <th>IdentificacaoParlamentar.UrlPaginaParticular</th>\n",
       "      <th>IdentificacaoParlamentar.EmailParlamentar</th>\n",
       "      <th>IdentificacaoParlamentar.UfParlamentar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5573</td>\n",
       "      <td>Abel Rebouças</td>\n",
       "      <td>Abel Rebouças São José</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>Senador</td>\n",
       "      <td>PDT</td>\n",
       "      <td>[{'CodigoMandato': '492', 'UfParlamentar': 'BA...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4981</td>\n",
       "      <td>Acir Gurgacz</td>\n",
       "      <td>Acir Marcos Gurgacz</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>Senador</td>\n",
       "      <td>PDT</td>\n",
       "      <td>[{'CodigoMandato': '515', 'UfParlamentar': 'RO...</td>\n",
       "      <td>916</td>\n",
       "      <td>http://www.senado.leg.br/senadores/img/fotos-o...</td>\n",
       "      <td>http://www25.senado.leg.br/web/senadores/senad...</td>\n",
       "      <td>https://acirgurgacz.com.br/</td>\n",
       "      <td>sen.acirgurgacz@senado.leg.br</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5918</td>\n",
       "      <td>Adilson Gomes</td>\n",
       "      <td>Adilson Gomes Silva</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>Senador</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'CodigoMandato': '526', 'UfParlamentar': 'PE...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5625</td>\n",
       "      <td>Adilson Silva dos Santos</td>\n",
       "      <td>Adilson Silva dos Santos</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>Senador</td>\n",
       "      <td>PEN</td>\n",
       "      <td>[{'CodigoMandato': '497', 'UfParlamentar': 'RS...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6026</td>\n",
       "      <td>Afonso Parente</td>\n",
       "      <td>Afonso Valter Parente Pinto</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>Senador</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'CodigoMandato': '578', 'UfParlamentar': 'RR...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CodigoParlamentar IdentificacaoParlamentar.NomeParlamentar  \\\n",
       "0              5573                            Abel Rebouças   \n",
       "1              4981                             Acir Gurgacz   \n",
       "2              5918                            Adilson Gomes   \n",
       "3              5625                 Adilson Silva dos Santos   \n",
       "4              6026                           Afonso Parente   \n",
       "\n",
       "  IdentificacaoParlamentar.NomeCompletoParlamentar  \\\n",
       "0                           Abel Rebouças São José   \n",
       "1                              Acir Marcos Gurgacz   \n",
       "2                              Adilson Gomes Silva   \n",
       "3                         Adilson Silva dos Santos   \n",
       "4                      Afonso Valter Parente Pinto   \n",
       "\n",
       "  IdentificacaoParlamentar.SexoParlamentar  \\\n",
       "0                                Masculino   \n",
       "1                                Masculino   \n",
       "2                                Masculino   \n",
       "3                                Masculino   \n",
       "4                                Masculino   \n",
       "\n",
       "  IdentificacaoParlamentar.FormaTratamento  \\\n",
       "0                                 Senador    \n",
       "1                                 Senador    \n",
       "2                                 Senador    \n",
       "3                                 Senador    \n",
       "4                                 Senador    \n",
       "\n",
       "  IdentificacaoParlamentar.SiglaPartidoParlamentar  \\\n",
       "0                                              PDT   \n",
       "1                                              PDT   \n",
       "2                                              NaN   \n",
       "3                                              PEN   \n",
       "4                                              NaN   \n",
       "\n",
       "                                    Mandatos.Mandato  \\\n",
       "0  [{'CodigoMandato': '492', 'UfParlamentar': 'BA...   \n",
       "1  [{'CodigoMandato': '515', 'UfParlamentar': 'RO...   \n",
       "2  [{'CodigoMandato': '526', 'UfParlamentar': 'PE...   \n",
       "3  [{'CodigoMandato': '497', 'UfParlamentar': 'RS...   \n",
       "4  [{'CodigoMandato': '578', 'UfParlamentar': 'RR...   \n",
       "\n",
       "  IdentificacaoParlamentar.CodigoPublicoNaLegAtual  \\\n",
       "0                                              NaN   \n",
       "1                                              916   \n",
       "2                                              NaN   \n",
       "3                                              NaN   \n",
       "4                                              NaN   \n",
       "\n",
       "         IdentificacaoParlamentar.UrlFotoParlamentar  \\\n",
       "0                                                NaN   \n",
       "1  http://www.senado.leg.br/senadores/img/fotos-o...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "       IdentificacaoParlamentar.UrlPaginaParlamentar  \\\n",
       "0                                                NaN   \n",
       "1  http://www25.senado.leg.br/web/senadores/senad...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "  IdentificacaoParlamentar.UrlPaginaParticular  \\\n",
       "0                                          NaN   \n",
       "1                  https://acirgurgacz.com.br/   \n",
       "2                                          NaN   \n",
       "3                                          NaN   \n",
       "4                                          NaN   \n",
       "\n",
       "  IdentificacaoParlamentar.EmailParlamentar  \\\n",
       "0                                       NaN   \n",
       "1             sen.acirgurgacz@senado.leg.br   \n",
       "2                                       NaN   \n",
       "3                                       NaN   \n",
       "4                                       NaN   \n",
       "\n",
       "  IdentificacaoParlamentar.UfParlamentar  \n",
       "0                                    NaN  \n",
       "1                                    NaN  \n",
       "2                                    NaN  \n",
       "3                                    NaN  \n",
       "4                                    NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def fetch_senadores_legislatura(legislatura: int) -> pd.DataFrame:\n",
    "    url = f\"{BASE}senador/lista/legislatura/{legislatura}.json\"\n",
    "    r = sess.get(url, params={\"v\":4}, timeout=90); r.raise_for_status()\n",
    "    root = safe_root_dict(r.json())\n",
    "    parls = (root.get(\"Parlamentares\") or {}).get(\"Parlamentar\") or []\n",
    "    df = pd.json_normalize(parls, sep=\".\")\n",
    "    for c in list(df.columns):\n",
    "        if c.lower().endswith(\"codigoparlamentar\"):\n",
    "            df = df.rename(columns={c: \"CodigoParlamentar\"}); break\n",
    "    df[\"CodigoParlamentar\"] = df[\"CodigoParlamentar\"].astype(str).str.strip()\n",
    "    return df\n",
    "\n",
    "LEGISLATURA = 56\n",
    "df_sen = fetch_senadores_legislatura(LEGISLATURA)\n",
    "df_sen.to_csv(os.path.join(OUT_DIR, f\"senadores_leg{LEGISLATURA}_lista.csv\"), index=False, sep=\";\", encoding=\"utf-8-sig\")\n",
    "df_sen.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7815477",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m codigos_exemplo = df_sen[\u001b[33m\"\u001b[39m\u001b[33mCodigoParlamentar\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m).head(\u001b[32m5\u001b[39m).tolist()\n\u001b[32m     15\u001b[39m dfs = [fetch_discursos_senador(c, INI, FIM) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m codigos_exemplo]\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m df_disc = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdfs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m dfs \u001b[38;5;28;01melse\u001b[39;00m pd.DataFrame()\n\u001b[32m     17\u001b[39m df_disc.to_csv(os.path.join(OUT_DIR, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdiscursos_amostra_leg\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mLEGISLATURA\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mINI\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFIM\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.csv\u001b[39m\u001b[33m\"\u001b[39m), index=\u001b[38;5;28;01mFalse\u001b[39;00m, sep=\u001b[33m\"\u001b[39m\u001b[33m;\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8-sig\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m df_disc.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/reshape/concat.py:382\u001b[39m, in \u001b[36mconcat\u001b[39m\u001b[34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[32m    380\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m op = \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m op.get_result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/reshape/concat.py:445\u001b[39m, in \u001b[36m_Concatenator.__init__\u001b[39m\u001b[34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[39m\n\u001b[32m    442\u001b[39m \u001b[38;5;28mself\u001b[39m.verify_integrity = verify_integrity\n\u001b[32m    443\u001b[39m \u001b[38;5;28mself\u001b[39m.copy = copy\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m objs, keys = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[32m    448\u001b[39m ndims = \u001b[38;5;28mself\u001b[39m._get_ndims(objs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/reshape/concat.py:507\u001b[39m, in \u001b[36m_Concatenator._clean_keys_and_objs\u001b[39m\u001b[34m(self, objs, keys)\u001b[39m\n\u001b[32m    504\u001b[39m     objs_list = \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[32m    506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m507\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo objects to concatenate\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    509\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    510\u001b[39m     objs_list = \u001b[38;5;28mlist\u001b[39m(com.not_none(*objs_list))\n",
      "\u001b[31mValueError\u001b[39m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "\n",
    "def fetch_discursos_senador(codigo: str, data_inicio: dt.date, data_fim: dt.date) -> pd.DataFrame:\n",
    "    frames = []\n",
    "    for ini, fim in make_windows(data_inicio, data_fim, 31):\n",
    "        url = f\"{BASE}senador/{codigo}/discursos.json\"\n",
    "        params = {\"dataInicio\": yyyymmdd(ini), \"dataFim\": yyyymmdd(fim)}\n",
    "        r = sess.get(url, params=params, timeout=90); r.raise_for_status()\n",
    "        pron = extract_pronunciamentos(r.json())\n",
    "        if not pron: continue\n",
    "        df = pd.json_normalize(pron, sep=\".\"); df[\"CodigoParlamentar\"] = str(codigo)\n",
    "        frames.append(df)\n",
    "    return pd.concat(frames, ignore_index=True, sort=False) if frames else pd.DataFrame()\n",
    "\n",
    "INI = dt.date(2025,1,1); FIM = dt.date(2025,9,16)\n",
    "codigos_exemplo = df_sen[\"CodigoParlamentar\"].astype(str).head(5).tolist()\n",
    "dfs = [fetch_discursos_senador(c, INI, FIM) for c in codigos_exemplo]\n",
    "df_disc = pd.concat([d for d in dfs if not d.empty], ignore_index=True, sort=False) if dfs else pd.DataFrame()\n",
    "df_disc.to_csv(os.path.join(OUT_DIR, f\"discursos_amostra_leg{LEGISLATURA}_{INI}_{FIM}.csv\"), index=False, sep=\";\", encoding=\"utf-8-sig\")\n",
    "df_disc.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56ffc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "def fetch_texto_integral(codigo_pronunciamento: str) -> str:\n",
    "    url = f\"{BASE}discurso/texto-integral/{codigo_pronunciamento}.txt\"\n",
    "    r = sess.get(url, headers={\"Accept\":\"text/plain\"}, timeout=90)\n",
    "    if r.status_code == 404: return \"\"\n",
    "    r.raise_for_status()\n",
    "    txt = re.sub(r\"\\s+\\n\", \"\\n\", r.text); txt = re.sub(r\"[ \\t]+\", \" \", txt).strip()\n",
    "    return txt\n",
    "\n",
    "def anexar_textos(df_disc: pd.DataFrame, salvar_arquivos: bool=True, pasta: str=\"_textos\") -> pd.DataFrame:\n",
    "    if \"CodigoPronunciamento\" not in df_disc.columns:\n",
    "        cand = [c for c in df_disc.columns if c.lower().endswith(\"codigopronunciamento\")]\n",
    "        if cand: df_disc = df_disc.rename(columns={cand[0]: \"CodigoPronunciamento\"})\n",
    "        else: raise KeyError(\"Coluna CodigoPronunciamento não encontrada.\")\n",
    "    os.makedirs(pasta, exist_ok=True)\n",
    "    paths = []\n",
    "    for cod in df_disc[\"CodigoPronunciamento\"].astype(str):\n",
    "        try:\n",
    "            txt = fetch_texto_integral(cod); path = os.path.join(pasta, f\"{cod}.txt\")\n",
    "            with open(path, \"w\", encoding=\"utf-8\") as f: f.write(txt)\n",
    "            paths.append(path)\n",
    "        except Exception as e:\n",
    "            print(f\"[TEXTO ERRO] {cod}: {e}\"); paths.append(\"\")\n",
    "    df_disc[\"ArquivoTextoIntegral\"] = paths\n",
    "    return df_disc\n",
    "\n",
    "if not df_disc.empty:\n",
    "    df_disc = anexar_textos(df_disc, True, TEXT_DIR)\n",
    "    df_disc.to_csv(os.path.join(OUT_DIR, f\"discursos_amostra_leg{LEGISLATURA}_{INI}_{FIM}_com_texto.csv\"), index=False, sep=\";\", encoding=\"utf-8-sig\")\n",
    "df_disc.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221c93e0",
   "metadata": {},
   "source": [
    "### (Opcional) TF‑IDF, embeddings e tópicos — preencha conforme sua necessidade"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
