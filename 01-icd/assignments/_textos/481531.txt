A SRA. DORA KAUFMAN (Para exposição de convidado.) – Bom dia, Senador, demais Senadores, participantes!
    O desafio de falar de um tema tão complexo em cinco minutos, eu acho, é um dos maiores desafios que eu já enfrentei. Vou colocar algumas questões. Várias já foram abordadas. Essas são a vantagem e a desvantagem de falar depois de tantos outros.
    Primeiro, diferentemente das demais tecnologias digitais, a inteligência artificial é uma tecnologia de propósito geral. Ela está em um bloco de tecnologias que moldam uma era. Provavelmente, tudo indica que é a tecnologia de propósito geral do século XXI. O que é uma tecnologia de propósito geral? Vou dar um exemplo, para ficar mais palpável. É, por exemplo, a máquina a vapor, a eletricidade, o computador. Dentro da inteligência artificial, na verdade, nós estamos falando... É um campo muito vasto, mas nós estamos tratando de uma técnica específica que está permeando praticamente todas as aplicações hoje de inteligência artificial. Ela foi pensada nos anos 80 e está em fase de implementação. Essa técnica é apenas um modelo estatístico de probabilidade baseado nos dados, que extrai informações úteis a partir dos dados; os algoritmos são treinados a partir de exemplos de dados.
    Pelo fato de ser um modelo estatístico de probabilidade, ela gera problemas intrínsecos à própria técnica, que é o fato, primeiro, de ser um modelo estatístico de probabilidade e de ter incerteza intrínseca, porque é uma probabilidade. Segundo, ele tem várias... Não vou ter tempo de entrar no mérito, mas ele tem várias limitações da técnica. É uma técnica muito restrita, muito inicial. Nós estamos falando de 2012 para cá, quando ela foi reconhecida. Então, é muito novo. Mas há essa técnica que está permeando quase tudo que está acontecendo em inteligência artificial hoje.
    Essa técnica, além de ser complexa, transforma-se ao longo do tempo; os modelos se transformam. Quanto mais há inserção de novos dados, esses dados impactam, e o modelo se transforma. Então, por exemplo, se a gente analisa a conformidade de um modelo na partida, não necessariamente ele continua... Aliás, a probabilidade é a de ele não continuar em conformidade, porque ele vai se modificando ao longo do tempo. Tudo isso são questões que agregam elementos complexos.
    Pela crescente relevância da IA na sociedade, de que muitos já falaram, que muitos já mencionaram, com as externalidades positivas e negativas, ou seja, com os benefícios e os malefícios, na última década foi reproduzida uma lista de princípios gerais relacionados à IA mundo afora. Só que esses princípios gerais, além de não serem universais, são difíceis de ser incorporados, traduzidos no modelo matemático, em termos matemáticos, para incorporar nos modelos que, como eu disse, são modelos estatísticos de probabilidade.
    Em paralelo a esse arcabouço de princípios gerais, cerca de 30 países lançaram suas estratégias de inteligência artificial. Dentre esses 30, destacam-se oito: Estados Unidos, Canadá, Reino Unido, China, Índia, França, Alemanha e Coreia. São estratégias mais robustas que servem como parâmetro para o desenvolvimento e o aperfeiçoamento da nossa estratégia de IA. Todos foram processos com uma ampla interação com a sociedade, com metas claras. E o componente fundamental nessas estratégias nacionais é a previsão de significativos volumes financeiros para sustentar a estratégia. É quase inócua uma estratégia se ela não tem como se financiar. Isso é fundamental, o que não existe, por exemplo, na proposta que foi lançada pelo ministério na Estratégia Brasileira de Inteligência Artificial.
    Por conta dessa complexidade, aparentemente, no mundo, só existe um projeto de regulamentação. Esse é um dado importante para a gente pensar. Existem diversos países onde o desenvolvimento e o uso da inteligência artificial estão avançados. No entanto, só há um projeto de regulamentação, que é, como já foi mencionado por vários, o projeto da Comissão Europeia que foi lançado no dia 25 de abril. Esse projeto foi desenvolvido, foi elaborado ao longo de três anos de debates. E, como também já foi dito, a previsão é a de que fique pelo menos três ou quatro anos em avaliação pela Comunidade Europeia. Ele tem 108 páginas, tem muitas lacunas, imprecisões, ambiguidades, idealismos, que deverão ser revistos antes de virar lei, porque o projeto de lei confere direitos que são invocados por pessoas e instituições perante os tribunais do país. Logo, um projeto de lei precisa ser preciso e incondicional, é claro.
    O Brasil está defasado comparativamente a outros países no desenvolvimento e adoção de tecnologia, mas os sistemas já estão presentes na área pública e na área privada. Por isso, é louvável a iniciativa da área pública, dos organismos governamentais, para proteger os cidadãos e as instituições dos potenciais danos, mas não se justifica a precipitação. Uma precipitação pode gerar soluções incompletas, equivocadas e não eficazes.
    Então, especificamente sobre o Projeto de Lei 872, na minha visão, com o pouco tempo que eu tenho para comentar, ele não atende a essa complexidade nem do ponto de vista dos desenvolvedores de tecnologia, nem do ponto de vista do usuário da tecnologia, porque são direitos e deveres distintos. A estrutura normativa do projeto é generalista, simplifica questões que não devem ser simplificadas.
    Quanto à questão do risco, é superimportante criar categorias com grau de risco, como também já foi mencionado principalmente pela Loren. É diferente você analisar o risco, por exemplo, de um sistema de recomendação do Netflix e o de um sistema de recomendação de um procedimento médico; não dá para analisar, enquadrar como uma única categoria. São riscos absolutamente distintos e potenciais de danos para o usuário também absolutamente distintos.
    O projeto contempla vários desses princípios gerais que eu mencionei anteriormente. Como eu também disse, primeiro, eles não têm conteúdo universal, e então precisaria ser explicitado qual é o conteúdo, e eles não são traduzidos em termos matemáticos. Então, como é que você incorpora princípios de garantia da autonomia para o usuário em um modelo estatístico de probabilidade? Vários das causas carecem de definição explícita. Não define o que seja ferramenta de segurança. Aí há vários! Se a gente tiver outra oportunidade, a gente vai entrar nos detalhes. Então, não leva em conta também as limitações da própria tecnologia. A questão do viés e preconceito é uma grande discussão no mundo. E, hoje, dadas as limitações dessa técnica, não é possível eliminar esse viés. O máximo é que existe um cuidado por parte dos desenvolvedores para mitigar os vieses que são originados tanto na decisão do desenvolvedor quanto da base de dados.
    Então, eu queria ressaltar as Cláusulas 4, 5, 6 e 7, porque elas não me parecem pertinentes a um projeto de lei. Elas me parecem mais pertinentes a um projeto estratégico.
    Outro aspecto central de que carece esse projeto de lei é que não prevê multa para situações de não conformidade, como não define como será a fiscalização, qual o órgão público que exercerá essa fiscalização, se será um órgão público centralizado, se será setorial.
    Em suma, eu acho que são louváveis – dado o avanço do uso pela sociedade e pela economia e os potenciais impactos negativos – iniciativas como essa, de tentar regulamentar, mas a gente tem que estar atento, porque não é à toa, não é uma coincidência que só haja um projeto de lei, que tem 108 páginas, que está sendo considerado muito vago, com muitas lacunas, e que vai ser objeto de uma discussão intensa na Comunidade Europeia e que, provavelmente, pelas primeiras impressões, vai ter grandes modificações, porque ele, como está, é inviável do ponto de vista de projeto de lei, de regulamentação.
    Então, eu acho que a gente tem que... Eu sinto muito desconforto com a precipitação. O Senador Eduardo Girão mencionou, em algum momento, a ideia de talvez já aprovar a lei no segundo semestre. Eu acho isso muito precipitado. Acho que a gente vai criar alguma coisa, uma regulamentação ineficaz, que vai trazer mais danos do que benefícios. É como se a gente pensasse assim: vamos fazer uma regulamentação para a eletricidade, para a cooptação. Mesmo, se a gente pegar a referência do Marco Civil da Internet, foi muito tempo de debate, foi uma interação muito grande com a sociedade. É alguma coisa nesse sentido, até mais complexo do que o Marco Civil da Internet.
    Então, eu estou à disposição. Nós temos o TIDD, o nosso programa, na PUC-SP. Nós temos um núcleo de pesquisadores, em que a gente discute. Faço parte também do Centro de Pesquisa da USP, com a Fapesp e a IBM também, voltado à inteligência artificial. Em suma, há vários desenvolvedores, pesquisadores, analistas na área acadêmica que estão à disposição. Mas é um processo.
    Muito obrigada pela oportunidade. Estou à disposição.