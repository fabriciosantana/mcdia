{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "788419ca",
   "metadata": {},
   "source": [
    "# HRPFP: previsão de fluxo com histórico + tempo real\n",
    "Implementação em PyTorch do modelo híbrido descrito em Ouyang et al. (2020) — Appl. Sci. 10(11):3788 — que combina codificadores LSTM para histórico e dados em tempo real (p.2, p.5)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd82a6b",
   "metadata": {},
   "source": [
    "### Visão geral do modelo (p.2, p.5, p.7–8)\n",
    "- Histórico: usa 7 passos temporais anteriores (mesmo horário em 7 dias) com 22 atributos: dia da semana, seção de tempo, index/lat/lon da parada e 17 contagens de POI (p.2, p.8).\n",
    "- Tempo real: usa as 4 janelas anteriores do dia em curso para prever os 2 próximos intervalos (p.2).\n",
    "- Fusão: projeções lineares para igualar formas (Equações 12–13), SoftMax para normalização e soma dos vetores de histórico e tempo real (Equações 14–15, p.5–7).\n",
    "- Decodificador: três camadas densas (Equações 16–18, p.7–8) e perda MSE entre previsto e real.\n",
    "- Antes do uso prático, o artigo seleciona o melhor raio de serviço para POIs com XGBoost e RMSE (p.7, p.10)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ed6ea2",
   "metadata": {},
   "source": [
    "### Imports e configuração (Equações 6–11 para LSTM, p.5)\n",
    "Usamos PyTorch para as LSTMs/MLP, SciKit-Learn para utilidades e NumPy para geração sintética."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e69525cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Garantir reprodutibilidade simples\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dbd716",
   "metadata": {},
   "source": [
    "### Hiperparâmetros alinhados ao artigo (p.2, p.7–8)\n",
    "Sequências de 7 (histórico) e 4 (tempo real), vetor de 22 atributos, projeção para 50 dimensões e decodificador de três camadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ff2e4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HRPFPConfig(history_seq_len=7, realtime_seq_len=4, pred_horizon=2, history_feature_dim=22, history_hidden=50, realtime_hidden=32, combined_dim=50, decoder_hidden1=32, decoder_hidden2=16, max_flow=300.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@dataclass\n",
    "class HRPFPConfig:\n",
    "    history_seq_len: int = 7\n",
    "    realtime_seq_len: int = 4\n",
    "    pred_horizon: int = 2\n",
    "    history_feature_dim: int = 22\n",
    "    history_hidden: int = 50  # saída 1x50 do codificador de histórico (p.8)\n",
    "    realtime_hidden: int = 32\n",
    "    combined_dim: int = 50\n",
    "    decoder_hidden1: int = 32\n",
    "    decoder_hidden2: int = 16\n",
    "    max_flow: float = 300.0  # usado para normalizar contagens\n",
    "\n",
    "config = HRPFPConfig()\n",
    "config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a97474",
   "metadata": {},
   "source": [
    "### Geração de dados sintéticos (p.2, p.7–8)\n",
    "Sem o dataset de Beijing, criamos um conjunto artificial com a mesma estrutura: 7 dias de histórico com 22 atributos normalizados (dia-da-semana + seção temporal + estação/lat/lon + 17 POIs), 4 medições em tempo real (contagens) e alvo em 2 passos futuros. As contagens são escaladas por um `max_flow` para representar a normalização Min–Max indicada pelo artigo (p.8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25fe4e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((600, 7, 22), (600, 4, 1), (600, 2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _build_feature_vector(dow: float, time_section: float, station_idx: float, lon: float, lat: float, poi_counts: np.ndarray) -> np.ndarray:\n",
    "    # 5 atributos espaço-temporais + 17 POIs = 22 dim (p.8)\n",
    "    base = [dow, time_section, station_idx, lon, lat]\n",
    "    return np.concatenate([np.array(base, dtype=np.float32), poi_counts.astype(np.float32)], axis=0)\n",
    "\n",
    "def _simulate_flow(base_level: float, time_section: int, noise_scale: float = 8.0) -> float:\n",
    "    # Padrão diário com pico matutino/vespertino e ruído\n",
    "    morning_peak = 1.3 * math.exp(-((time_section - 7) ** 2) / 18)\n",
    "    evening_peak = 1.1 * math.exp(-((time_section - 17) ** 2) / 20)\n",
    "    seasonal = 0.2 * math.sin(time_section / 24 * 2 * math.pi)\n",
    "    return max(5.0, base_level * (1 + morning_peak + evening_peak + seasonal) + np.random.normal(0, noise_scale))\n",
    "\n",
    "def generate_synthetic_sample(cfg: HRPFPConfig, rng: np.random.Generator) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    station_idx = rng.integers(0, 20)\n",
    "    time_section = int(rng.integers(0, 24))\n",
    "    base_day = int(rng.integers(0, 30))\n",
    "    lon = 0.5 + rng.normal(0, 0.05)\n",
    "    lat = 0.5 + rng.normal(0, 0.05)\n",
    "    poi_counts = rng.uniform(0, 1, 17)\n",
    "    base_level = 40 + 30 * poi_counts.mean() + 5 * (station_idx / 20)\n",
    "\n",
    "    history_seq = []\n",
    "    for i in range(cfg.history_seq_len):\n",
    "        dow = ((base_day - (cfg.history_seq_len - i)) % 7) / 6\n",
    "        feat = _build_feature_vector(dow, time_section / 23, station_idx / 20, lon, lat, poi_counts)\n",
    "        history_seq.append(feat)\n",
    "    history_seq = np.stack(history_seq)\n",
    "\n",
    "    realtime_seq = []\n",
    "    targets = []\n",
    "    for step in range(cfg.realtime_seq_len + cfg.pred_horizon):\n",
    "        flow = _simulate_flow(base_level, time_section + step) / cfg.max_flow\n",
    "        if step < cfg.realtime_seq_len:\n",
    "            realtime_seq.append([flow])\n",
    "        else:\n",
    "            targets.append(flow)\n",
    "    realtime_seq = np.array(realtime_seq, dtype=np.float32)\n",
    "    targets = np.array(targets, dtype=np.float32)\n",
    "    return history_seq.astype(np.float32), realtime_seq, targets\n",
    "\n",
    "def generate_dataset(cfg: HRPFPConfig, n_samples: int, seed: int = 0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    history, realtime, targets = [], [], []\n",
    "    for _ in range(n_samples):\n",
    "        h, r, t = generate_synthetic_sample(cfg, rng)\n",
    "        history.append(h)\n",
    "        realtime.append(r)\n",
    "        targets.append(t)\n",
    "    return np.stack(history), np.stack(realtime), np.stack(targets)\n",
    "\n",
    "raw_history, raw_realtime, raw_targets = generate_dataset(config, n_samples=600, seed=SEED)\n",
    "raw_history.shape, raw_realtime.shape, raw_targets.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d72b0a",
   "metadata": {},
   "source": [
    "### Dataset e DataLoaders com normalização simples (p.8)\n",
    "O artigo enfatiza a normalização das 22 features (Min–Max). As contagens em tempo real e os alvos já estão divididos por `max_flow`; as features simuladas estão em [0,1] por construção. Se desejar, basta substituir o gerador pela leitura do dataset real de AFC/POI seguindo o mesmo formato tensorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "818a4728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 120)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class HRPFPSyntheticDataset(Dataset):\n",
    "    def __init__(self, history: np.ndarray, realtime: np.ndarray, targets: np.ndarray):\n",
    "        self.history = torch.from_numpy(history)\n",
    "        self.realtime = torch.from_numpy(realtime)\n",
    "        self.targets = torch.from_numpy(targets)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.history)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.history[idx], self.realtime[idx], self.targets[idx]\n",
    "\n",
    "full_dataset = HRPFPSyntheticDataset(raw_history, raw_realtime, raw_targets)\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size], generator=torch.Generator().manual_seed(SEED))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "len(train_dataset), len(val_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a786a47",
   "metadata": {},
   "source": [
    "### Ajuste de raio de serviço para POIs (p.7, p.10, Eq.19)\n",
    "O artigo escolhe o raio que minimiza o RMSE ao combinar POIs via XGBoost. Abaixo está uma versão simplificada/toy usando as 17 features de POI sintéticas: escalonamos as contagens por um fator dependente do raio e testamos diferentes valores com XGBoostRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec40c096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,\n",
       " [(100, 0.04946607125723421),\n",
       "  (200, 0.04946607125723421),\n",
       "  (300, 0.04946607125723421)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "def estimate_best_radius(poi_matrix: np.ndarray, target: np.ndarray, radii=(100, 200, 300, 400, 500)):\n",
    "    scores = []\n",
    "    for r in radii:\n",
    "        weight = math.exp(-abs(r - 300) / 200)  # simula decaimento de relevância fora do ótimo (~300 m, ver p.10)\n",
    "        X = poi_matrix * weight\n",
    "        model = XGBRegressor(\n",
    "            max_depth=4, learning_rate=0.05, n_estimators=120, subsample=0.8, colsample_bytree=0.9,\n",
    "            objective='reg:squarederror', random_state=SEED\n",
    "        )\n",
    "        model.fit(X, target)\n",
    "        preds = model.predict(X)\n",
    "        rmse = math.sqrt(mean_squared_error(target, preds))\n",
    "        scores.append((r, rmse))\n",
    "    scores.sort(key=lambda x: x[1])\n",
    "    return scores[0][0], scores\n",
    "\n",
    "poi_features = raw_history[:, 0, 5:]  # 17 POIs do primeiro passo histórico apenas para demo\n",
    "best_radius, radius_scores = estimate_best_radius(poi_features, raw_targets.mean(axis=1))\n",
    "best_radius, radius_scores[:3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cf2741",
   "metadata": {},
   "source": [
    "### Arquitetura HRPFP em PyTorch (Equações 12–18, p.5–8)\n",
    "Segue a sequência do artigo: codificador LSTM de histórico (1×50), codificador LSTM de tempo real, projeções lineares + SoftMax para combinar vetores e decodificador de 3 camadas com Sigmoid na segunda camada. A perda utilizada é MSE entre `P` e o alvo (p.7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cb65b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HRPFPModel(nn.Module):\n",
    "    def __init__(self, cfg: HRPFPConfig):\n",
    "        super().__init__()\n",
    "        self.history_encoder = nn.LSTM(input_size=cfg.history_feature_dim, hidden_size=cfg.history_hidden, batch_first=True)\n",
    "        self.realtime_encoder = nn.LSTM(input_size=1, hidden_size=cfg.realtime_hidden, batch_first=True)\n",
    "        self.history_proj = nn.Linear(cfg.history_hidden, cfg.combined_dim)\n",
    "        self.realtime_proj = nn.Linear(cfg.realtime_hidden, cfg.combined_dim)\n",
    "        self.decoder1 = nn.Linear(cfg.combined_dim, cfg.decoder_hidden1)\n",
    "        self.decoder2 = nn.Linear(cfg.decoder_hidden1, cfg.decoder_hidden2)\n",
    "        self.output = nn.Linear(cfg.decoder_hidden2, cfg.pred_horizon)\n",
    "\n",
    "    def forward(self, history_x: torch.Tensor, realtime_x: torch.Tensor):\n",
    "        # history_x: (batch, seq_len, 22)\n",
    "        _, (h_n, _) = self.history_encoder(history_x)\n",
    "        hist_vec = self.history_proj(h_n[-1])\n",
    "        _, (r_n, _) = self.realtime_encoder(realtime_x)\n",
    "        real_vec = self.realtime_proj(r_n[-1])\n",
    "        hist_soft = torch.softmax(hist_vec, dim=-1)\n",
    "        real_soft = torch.softmax(real_vec, dim=-1)\n",
    "        info = hist_soft + real_soft\n",
    "        d1 = self.decoder1(info)\n",
    "        d2 = torch.sigmoid(self.decoder2(d1))\n",
    "        return self.output(d2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3722106",
   "metadata": {},
   "source": [
    "### Treino rápido em dados sintéticos (p.7)\n",
    "Otimizamos a MSE (equivalente a minimizar RMSE² do Eq.19) com Adam. Com dados reais, ajustaríamos épocas e early stopping; aqui rodamos poucas iterações para demonstrar o fluxo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f4cc72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00 — train RMSE: 0.5979, val RMSE: 0.5060\n",
      "Epoch 05 — train RMSE: 0.0947, val RMSE: 0.0955\n",
      "Epoch 10 — train RMSE: 0.0933, val RMSE: 0.0929\n",
      "Epoch 14 — train RMSE: 0.0933, val RMSE: 0.0927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.09330896592144161, 0.09271418168162561)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = HRPFPModel(config).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "for epoch in range(15):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for hist_batch, rt_batch, tgt_batch in train_loader:\n",
    "        hist_batch = hist_batch.to(device)\n",
    "        rt_batch = rt_batch.to(device)\n",
    "        tgt_batch = tgt_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(hist_batch, rt_batch)\n",
    "        loss = criterion(preds, tgt_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * len(hist_batch)\n",
    "\n",
    "    train_rmse = math.sqrt(running_loss / len(train_loader.dataset))\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for hist_batch, rt_batch, tgt_batch in val_loader:\n",
    "            preds = model(hist_batch.to(device), rt_batch.to(device))\n",
    "            loss = criterion(preds.cpu(), tgt_batch)\n",
    "            val_loss += loss.item() * len(hist_batch)\n",
    "    val_rmse = math.sqrt(val_loss / len(val_loader.dataset))\n",
    "\n",
    "    train_history.append(train_rmse)\n",
    "    val_history.append(val_rmse)\n",
    "    if epoch % 5 == 0 or epoch == 14:\n",
    "        print(f'Epoch {epoch:02d} — train RMSE: {train_rmse:.4f}, val RMSE: {val_rmse:.4f}')\n",
    "\n",
    "train_history[-1], val_history[-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7724488",
   "metadata": {},
   "source": [
    "### Avaliação qualitativa das previsões (p.12–13)\n",
    "Mostramos alguns pares real×previsto (contagens desscaladas). No artigo, as Figuras 9–12 comparam curvas de tempo; aqui apenas listamos valores para verificar que o modelo captura tendências."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcf41be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemplo 0: Real [116.3  96.8] | Previsto [99.7 97.9]\n",
      "Exemplo 1: Real [108.4 106.2] | Previsto [99.7 97.9]\n",
      "Exemplo 2: Real [53.5 54.9] | Previsto [99.6 97.9]\n",
      "Exemplo 3: Real [53.9 57.5] | Previsto [99.6 97.9]\n",
      "Exemplo 4: Real [129.  107.5] | Previsto [99.8 97.9]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sample_hist, sample_rt, sample_tgt = next(iter(val_loader))\n",
    "    preds = model(sample_hist.to(device), sample_rt.to(device)).cpu()\n",
    "\n",
    "for i in range(5):\n",
    "    real_counts = (sample_tgt[i] * config.max_flow).numpy()\n",
    "    pred_counts = (preds[i] * config.max_flow).numpy()\n",
    "    print(f'Exemplo {i}: Real {real_counts.round(1)} | Previsto {pred_counts.round(1)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de22087d",
   "metadata": {},
   "source": [
    "### Próximos passos sugeridos\n",
    "- Substituir o gerador sintético pelo dataset real de AFC/POI, mantendo os tensores `history_x`, `realtime_x` e alvos normalizados.\n",
    "- Implementar a coleta de POIs por raio real via API (Figura 3, p.8) e alimentar `estimate_best_radius` com as agregações reais.\n",
    "- Reproduzir as comparações com séries temporais e LSTM puro (Seção 4, p.10–13) para validar contra os números do artigo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
