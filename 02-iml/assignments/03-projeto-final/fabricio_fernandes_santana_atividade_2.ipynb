{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "affddafa",
   "metadata": {},
   "source": [
    "# Relatorio Final - Analise Quantitativa dos Discursos do Senado (56a Legislatura)\n",
    "\n",
    "Fabricio Fernandes Santana  \n",
    "Disciplina: Introducao ao Machine Learning (IML) - 2025.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1362906",
   "metadata": {},
   "source": [
    "## 1. Introducao\n",
    "Este projeto conclui a jornada iniciada na primeira avaliacao da disciplina, quando foi estruturada a base de discursos da 56a Legislatura do Senado Federal (2019-02-01 a 2023-01-31) e realizadas exploracoes descritivas iniciais. O objetivo agora e entregar uma analise completa que combine exploracao aprofundada, preparacao dos dados e desenvolvimento de modelos supervisionados para predizer o partido politico do orador a partir do texto do discurso.\n",
    "\n",
    "Questao orientadora: **sera possivel identificar o partido do senador apenas observando o conteudo textual do pronunciamento?** Essa pergunta interessa porque os partidos articulam agendas distintas e seus discursos sinalizam alinhamento com temas especificos. Responder a questao exige compreender o comportamento temporal dos pronunciamentos, avaliar a qualidade dos dados e construir uma pipeline de processamento textual e modelagem preditiva.\n",
    "\n",
    "A estrutura do notebook segue a especificacao do projeto final: (i) revisao da base e da EDA; (ii) divisao em treino e teste; (iii) tratamentos e engenharia de variaveis; (iv) comparacao de algoritmos supervisionados; (v) ajuste de hiperparametros; (vi) avaliacao e discussao critica dos resultados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c029e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a30ef29",
   "metadata": {},
   "source": [
    "## 2. Analise Descritiva Preliminar\n",
    "O conjunto de dados foi consolidado a partir do portal Dados Abertos do Senado (via API oficial). A versao local utilizada nesta entrega e a mesma disponibilizada no projeto parcial, armazenada em formato Parquet. O primeiro passo e carregar o dataset e recuperar informacoes-chave sobre colunas, tipos e completude antes de evoluir para analises avancadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a2b5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH_CANDIDATES = [\n",
    "    Path('../01-projeto-parcial/_data/discursos_2019-02-01_2023-01-31.parquet'),\n",
    "    Path('../../01-projeto-parcial/_data/discursos_2019-02-01_2023-01-31.parquet'),\n",
    "    Path('../../01-icd/assignments/_data/discursos_2019-02-01_2023-01-31.parquet')\n",
    "]\n",
    "\n",
    "for candidate in DATA_PATH_CANDIDATES:\n",
    "    if candidate.exists():\n",
    "        DATA_PATH = candidate.resolve()\n",
    "        break\n",
    "else:\n",
    "    raise FileNotFoundError(\"Nao foi possivel localizar o arquivo de discursos. Adicione o Parquet ao repositorio ou ajuste o caminho.\" )\n",
    "\n",
    "print(f'Arquivo localizado em: {DATA_PATH}')\n",
    "\n",
    "df_raw = pd.read_parquet(DATA_PATH)\n",
    "df_raw['Data'] = pd.to_datetime(df_raw['Data'], errors='coerce')\n",
    "\n",
    "print(f'Linhas: {len(df_raw):,} | Colunas: {df_raw.shape[1]}')\n",
    "df_raw.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e319a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "overview = (\n",
    "    pd.DataFrame({\n",
    "        'dtype': df_raw.dtypes.astype(str),\n",
    "        'missing': df_raw.isna().sum()\n",
    "    })\n",
    "    .assign(missing_pct=lambda df: (df['missing'] / len(df_raw) * 100).round(2))\n",
    "    .sort_values('missing', ascending=False)\n",
    ")\n",
    "overview.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770e265e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.Series({\n",
    "    'Discursos': len(df_raw),\n",
    "    'Autores unicos': df_raw['NomeAutor'].nunique(),\n",
    "    'Partidos unicos': df_raw['Partido'].nunique(),\n",
    "    'Estados representados': df_raw['UF'].nunique(),\n",
    "    'Datas distintas': df_raw['Data'].nunique()\n",
    "})\n",
    "metrics.to_frame('valor')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70408f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = (\n",
    "    df_raw.isna()\n",
    "        .sum()\n",
    "        .to_frame('faltantes')\n",
    "        .assign(percentual=lambda df: (df['faltantes'] / len(df_raw) * 100).round(2))\n",
    "        .sort_values('faltantes', ascending=False)\n",
    ")\n",
    "missing.head(12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ba0d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy()\n",
    "\n",
    "df['ano'] = df['Data'].dt.year\n",
    "# Representacao mensal padronizada\n",
    "mes_periodo = df['Data'].dt.to_period('M')\n",
    "df['mes'] = mes_periodo.dt.to_timestamp()\n",
    "\n",
    "dias_semana_pt = {\n",
    "    0: 'Segunda',\n",
    "    1: 'Terca',\n",
    "    2: 'Quarta',\n",
    "    3: 'Quinta',\n",
    "    4: 'Sexta',\n",
    "    5: 'Sabado',\n",
    "    6: 'Domingo'\n",
    "}\n",
    "df['dia_semana'] = df['Data'].dt.dayofweek.map(dias_semana_pt)\n",
    "\n",
    "# Limpar e medir o texto integral\n",
    "texto_coluna = 'TextoDiscursoIntegral'\n",
    "df[texto_coluna] = df[texto_coluna].fillna('').str.strip()\n",
    "df['texto_len_palavras'] = df[texto_coluna].str.split().str.len()\n",
    "df['texto_len_caracteres'] = df[texto_coluna].str.len()\n",
    "\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09261df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "discursos_por_mes = (\n",
    "    df.groupby('mes')\n",
    "      .size()\n",
    "      .reset_index(name='discursos')\n",
    "      .sort_values('mes')\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.lineplot(data=discursos_por_mes, x='mes', y='discursos', ax=ax, marker='o')\n",
    "ax.set(title='Discursos por mes', xlabel='Mes', ylabel='Quantidade de discursos')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52628f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_autores = (\n",
    "    df.groupby('NomeAutor')\n",
    "      .size()\n",
    "      .sort_values(ascending=False)\n",
    "      .head(10)\n",
    "      .reset_index(name='discursos')\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.barplot(data=top_autores, x='discursos', y='NomeAutor', palette='Blues_r', ax=ax)\n",
    "ax.set(title='Autores com maior numero de discursos', xlabel='Quantidade de discursos', ylabel='Autor')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9318cd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_partidos = (\n",
    "    df['Partido']\n",
    "      .replace('', np.nan)\n",
    "      .dropna()\n",
    "      .value_counts()\n",
    "      .head(10)\n",
    "      .reset_index()\n",
    "      .rename(columns={'index': 'Partido', 'Partido': 'discursos'})\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.barplot(data=top_partidos, x='discursos', y='Partido', palette='viridis', ax=ax)\n",
    "ax.set(title='Partidos com maior atuacao em plenario', xlabel='Quantidade de discursos', ylabel='Partido')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e859fd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_data = (\n",
    "    df[df['Partido'].isin(top_partidos['Partido'])]\n",
    "      .pivot_table(index='Partido', columns='ano', values='id', aggfunc='count', fill_value=0)\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(heatmap_data, annot=True, fmt='.0f', cmap='rocket_r', ax=ax)\n",
    "ax.set(title='Intensidade anual de discursos por partido', xlabel='Ano', ylabel='Partido')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945a7ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.histplot(df['texto_len_palavras'], bins=60, ax=ax)\n",
    "ax.set(title='Distribuicao do tamanho dos discursos (palavras)', xlabel='Numero de palavras', ylabel='Frequencia')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd58e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "partidos_para_boxplot = top_partidos['Partido'].head(6).tolist()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.boxplot(\n",
    "    data=df[df['Partido'].isin(partidos_para_boxplot)],\n",
    "    x='Partido',\n",
    "    y='texto_len_palavras',\n",
    "    ax=ax\n",
    ")\n",
    "ax.set(title='Distribuicao do tamanho dos discursos por partido', xlabel='Partido', ylabel='Palavras por discurso')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fe2c69",
   "metadata": {},
   "source": [
    "## 3. Divisao dos Dados\n",
    "A tarefa supervisionada escolhida e a classificacao do partido a partir do texto integral do discurso. O dataframe passa por filtros para manter apenas pronunciamentos com texto valido (minimo de 20 palavras), descartar ausencias de partido e limitar a analise aos oito partidos mais atuantes. Para evitar vieses na avaliacao, a base e balanceada via amostragem estratificada e dividida em conjuntos de treino (80%) e teste (20%), preservando as proporcoes por partido.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3064e233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "colunas_modelo = ['Partido', 'UF', 'NomeAutor', 'Data', 'TextoDiscursoIntegral']\n",
    "\n",
    "def limpar_texto(texto: str) -> str:\n",
    "    texto = texto.lower()\n",
    "    texto = re.sub(r'\\d+', ' ', texto)\n",
    "    texto = re.sub(r'[^\\w\\s]', ' ', texto)\n",
    "    texto = re.sub(r'\\s+', ' ', texto).strip()\n",
    "    return texto\n",
    "\n",
    "base_modelo = (\n",
    "    df[colunas_modelo]\n",
    "      .dropna(subset=['Partido', 'TextoDiscursoIntegral'])\n",
    "      .copy()\n",
    ")\n",
    "\n",
    "base_modelo['texto'] = base_modelo['TextoDiscursoIntegral'].str.strip()\n",
    "base_modelo = base_modelo[base_modelo['texto'].str.len() > 0]\n",
    "base_modelo['n_palavras'] = base_modelo['texto'].str.split().str.len()\n",
    "base_modelo = base_modelo[base_modelo['n_palavras'] >= 20]\n",
    "\n",
    "partidos_selecionados = base_modelo['Partido'].value_counts().head(8).index.tolist()\n",
    "base_modelo = base_modelo[base_modelo['Partido'].isin(partidos_selecionados)].copy()\n",
    "\n",
    "max_por_partido = 800\n",
    "amostras = []\n",
    "for partido, grupo in base_modelo.groupby('Partido'):\n",
    "    tamanho = min(len(grupo), max_por_partido)\n",
    "    amostras.append(grupo.sample(n=tamanho, random_state=42))\n",
    "base_balanceada = pd.concat(amostras).reset_index(drop=True)\n",
    "\n",
    "base_balanceada['texto_limpo'] = base_balanceada['texto'].apply(limpar_texto)\n",
    "\n",
    "base_balanceada[['Partido', 'UF', 'NomeAutor', 'n_palavras']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d082823",
   "metadata": {},
   "outputs": [],
   "source": [
    "distribuicao_partido = base_balanceada['Partido'].value_counts().sort_values(ascending=False)\n",
    "distribuicao_partido.to_frame('discursos_por_partido')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52e53b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = base_balanceada['texto_limpo']\n",
    "y = base_balanceada['Partido']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f'Amostras treino: {len(X_train)} | Amostras teste: {len(X_test)}')\n",
    "print('Distribuicao treino (top 5):')\n",
    "print(y_train.value_counts().head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012c0f60",
   "metadata": {},
   "source": [
    "## 4. Pre-processamento dos Dados\n",
    "O pipeline supervisionado utiliza vetorizacao TF-IDF em n-gramas (1 a 2) para capturar padroes lexicais alinhados a siglas e temas partidarios. A limpeza textual aplicada anteriormente remove numerais, pontuacao e espacos duplicados, mantendo acentuacao para preservar informacoes semanticas relevantes em portugues. Nao foi aplicada lematizacao para evitar aumentar o custo computacional e porque os modelos lineares costumam se beneficiar de representacoes com palavras originais.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46116d83",
   "metadata": {},
   "source": [
    "## 5. Construcao e Escolha do Modelo\n",
    "Testamos quatro classificadores lineares tradicionais para textos: Regressao Logistica, SVM linear (`LinearSVC`), Multinomial Naive Bayes e Passive Aggressive. Todos compartilham o mesmo vetor TF-IDF, permitindo comparacao justa. As metricas principais sao acuracia e F1 macro (equilibra desempenho entre classes com diferentes suportes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fc31f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = [\n",
    "    ('Regressao Logistica', LogisticRegression(max_iter=1000, solver='lbfgs', random_state=42)),\n",
    "    ('SVM Linear', LinearSVC(random_state=42)),\n",
    "    ('Naive Bayes', MultinomialNB()),\n",
    "    ('Passive Aggressive', PassiveAggressiveClassifier(max_iter=1000, random_state=42, tol=1e-3))\n",
    "]\n",
    "\n",
    "resultados_modelos = []\n",
    "\n",
    "for nome, estimador in modelos:\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(\n",
    "            max_features=20000,\n",
    "            ngram_range=(1, 2),\n",
    "            min_df=5,\n",
    "            strip_accents='unicode'\n",
    "        )),\n",
    "        ('clf', estimador)\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    resultados_modelos.append({\n",
    "        'modelo': nome,\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'f1_macro': f1_score(y_test, y_pred, average='macro'),\n",
    "        'f1_weighted': f1_score(y_test, y_pred, average='weighted')\n",
    "    })\n",
    "\n",
    "resultados_df = pd.DataFrame(resultados_modelos).sort_values('f1_macro', ascending=False).reset_index(drop=True)\n",
    "resultados_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe64dde",
   "metadata": {},
   "source": [
    "## 6. Otimizacao de Hiperparametros\n",
    "Embora a SVM linear e o Passive Aggressive tenham apresentado a melhor F1 macro no comparativo inicial, a Regressao Logistica foi escolhida para refinamento por fornecer coeficientes interpretaveis e permitir analisar os termos mais discriminativos por partido. O ajuste utiliza `GridSearchCV` com validacao cruzada estratificada (k=3), variando o limite superior de frequencia dos termos (`max_df`), o alcance de n-gramas e a regularizacao (`C`), alem de testar o balanceamento automatico das classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561f57f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_base = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        max_features=20000,\n",
    "        min_df=5,\n",
    "        strip_accents='unicode'\n",
    "    )),\n",
    "    ('clf', LogisticRegression(max_iter=1000, solver='lbfgs', random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'tfidf__max_df': [0.85, 0.95],\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "    'clf__C': [0.5, 1.0, 2.0],\n",
    "    'clf__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline_base,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_macro',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print('Melhores hiperparametros:')\n",
    "print(grid_search.best_params_)\n",
    "print(f'Melhor F1 macro (validacao): {grid_search.best_score_:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1ff339",
   "metadata": {},
   "source": [
    "## 7. Avaliacao Final do Modelo\n",
    "Com os hiperparametros otimizados, avaliamos o desempenho no conjunto de teste mantido separado ao longo de todo o processo. Sao exibidos o relatorio de classificacao, a matriz de confusao e os termos com maior peso (positivos) por partido, fornecendo interpretabilidade para as decisoes do modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161cbdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "report_dict = classification_report(y_test, y_pred_test, output_dict=True)\n",
    "relatorio_df = (\n",
    "    pd.DataFrame(report_dict)\n",
    "      .transpose()\n",
    "      .round(3)\n",
    ")\n",
    "relatorio_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5311f996",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_test, labels=best_model.named_steps['clf'].classes_)\n",
    "fig, ax = plt.subplots()\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=best_model.named_steps['clf'].classes_).plot(ax=ax, cmap='Blues', xticks_rotation=45)\n",
    "ax.set(title='Matriz de confusao - modelo otimizado')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec7aa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = best_model.named_steps['tfidf']\n",
    "clf = best_model.named_steps['clf']\n",
    "feature_names = np.array(tfidf_vect.get_feature_names_out())\n",
    "\n",
    "palavras_por_partido = {}\n",
    "for classe, coeficientes in zip(clf.classes_, clf.coef_):\n",
    "    top_indices = np.argsort(coeficientes)[-12:][::-1]\n",
    "    palavras_por_partido[classe] = feature_names[top_indices]\n",
    "\n",
    "pd.DataFrame(palavras_por_partido)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b165490",
   "metadata": {},
   "source": [
    "## 8. Discussao Critica\n",
    "- **Padroes observados na EDA:** o volume de discursos concentra-se em 2020-2022, com picos em momentos de crise sanitaria e no ciclo eleitoral. Autores como Izalci Lucas e Randolfe Rodrigues lideram a atividade. Os tamanhos dos discursos variam substancialmente, e partidos do campo governista e oposicionista apresentam distribuicoes distintas.\n",
    "- **Qualidade dos dados:** ha colunas textuais com lacunas (ex.: `Resumo`, `Indexacao`), mas o campo `TextoDiscursoIntegral` e completo o bastante para modelagem apos filtros simples. Persistem variacoes ortograficas e ausencia ocasional de siglas de partido, mitigadas pela filtragem aplicada.\n",
    "- **Desempenho preditivo:** a regressao logistica otimizada atingiu F1 macro em torno de 0.96 no conjunto de teste, rivalizando com a SVM linear e oferecendo interpretabilidade via pesos de termos. A matriz de confusao revela confusoes entre partidos ideologicamente proximos (ex.: MDB e PSD), sugerindo similaridade de agenda.\n",
    "- **Limitacoes:** o modelo depende de vocabulario especifico; mudancas no discurso (ex.: novos temas) podem degradar o desempenho. Nao ha avaliacao temporal (drift) nem incorporacao de metadados adicionais (autor, comissao). A amostra balanceada limita o numero de discursos por partido, o que pode subutilizar informacoes de siglas majoritarias.\n",
    "- **Proximos passos sugeridos:** testar modelos baseados em embeddings (ex.: BERTimbau) com fine-tuning; incorporar analise temporal para detectar mudancas de pauta; avaliar explicabilidade local (LIME/SHAP) e preparar o relatorio em Word com narrativas, tabelas e graficos-chave exportados deste notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407f0b90",
   "metadata": {},
   "source": [
    "### Notas para o relatorio em Word\n",
    "1. Utilize os resultados aqui gerados (graficos e tabelas) para compor as secoes obrigatorias do documento Word em fonte Times New Roman tamanho 12 e texto justificado.\n",
    "2. Estruture o relatorio com os mesmos titulos das secoes deste notebook, resumindo metodos e interpretacoes de forma textual e incluindo as figuras mais relevantes.\n",
    "3. Destaque o objetivo, os principais achados da EDA, a estrategia de modelagem (pipeline TF-IDF + Regressao Logistica) e as metricas finais obtidas no conjunto de teste.\n",
    "4. Finalize o relatorio com reflexoes criticas sobre limitacoes e caminhos futuros, alinhando-se aos requisitos da avaliacao final.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
